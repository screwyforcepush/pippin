
##### my_digital_being/framework/activity_decorator.py #####
import functools
import logging
from typing import Callable, Any, Dict, List, Optional
from datetime import datetime
import json

logger = logging.getLogger(__name__)


def activity(
    name: str,
    energy_cost: float = 0.2,
    cooldown: int = 0,
    required_skills: Optional[List[str]] = None,
):
    """Decorator for activity classes."""

    def decorator(cls):
        cls.activity_name = name
        cls.energy_cost = energy_cost
        cls.cooldown = cooldown
        cls.required_skills = required_skills or []
        cls.last_execution = None

        # Add metadata to the class
        cls.metadata = {
            "name": name,
            "energy_cost": energy_cost,
            "cooldown": cooldown,
            "required_skills": required_skills,
        }

        # Wrap the execute method
        original_execute = cls.execute

        @functools.wraps(original_execute)
        async def wrapped_execute(self, *args, **kwargs):
            try:
                # Pre-execution checks
                if not self._can_execute():
                    logger.warning(f"Activity {name} is on cooldown")
                    return ActivityResult(
                        success=False, error="Activity is on cooldown"
                    )

                # Log activity start
                logger.info(f"Starting activity: {name}")
                start_time = datetime.now()

                # Execute the activity
                result = await original_execute(self, *args, **kwargs)

                # Post-execution processing
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                cls.last_execution = end_time

                # Log activity completion
                logger.info(f"Completed activity: {name} in {duration:.2f} seconds")

                return result

            except Exception as e:
                logger.error(f"Error in activity {name}: {e}")
                return ActivityResult(success=False, error=str(e))

        cls.execute = wrapped_execute
        return cls

    return decorator


class ActivityResult:
    """Class to store activity execution results."""

    def __init__(
        self,
        success: bool,
        data: Optional[Any] = None,
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ):
        self.success = success
        self.data = data
        self.error = error
        self.metadata = metadata or {}
        self.timestamp = datetime.now()

    def to_dict(self) -> Dict[str, Any]:
        """Convert result to dictionary format."""
        data_dict = {}
        if self.data:
            if hasattr(self.data, "to_dict"):
                data_dict = self.data.to_dict()
            elif isinstance(self.data, dict):
                data_dict = self.data
            else:
                try:
                    data_dict = json.loads(json.dumps(self.data))
                except:
                    data_dict = str(self.data)

        return {
            "success": self.success,
            "data": data_dict,
            "error": self.error,
            "metadata": self.metadata,
            "timestamp": self.timestamp.isoformat(),
        }

    @classmethod
    def success_result(
        cls, data: Optional[Any] = None, metadata: Optional[Dict[str, Any]] = None
    ):
        """Create a successful result."""
        return cls(success=True, data=data, metadata=metadata)

    @classmethod
    def error_result(cls, error: str, metadata: Optional[Dict[str, Any]] = None):
        """Create an error result."""
        return cls(success=False, error=error, metadata=metadata)


class ActivityBase:
    """Base class for all activities."""

    def __init__(self):
        self.result = None
        self.last_execution: Optional[datetime] = None
        self.cooldown: int = 0

    def _can_execute(self) -> bool:
        """Check if the activity can be executed."""
        if self.last_execution is None:
            return True

        now = datetime.now()
        time_since_last = (now - self.last_execution).total_seconds()
        return time_since_last >= self.cooldown

    def get_result(self) -> Dict[str, Any]:
        """Get the result of the activity execution."""
        if isinstance(self.result, ActivityResult):
            return self.result.to_dict()
        return {
            "success": bool(self.result),
            "data": self.result if self.result else None,
            "error": None,
            "timestamp": datetime.now().isoformat(),
        }

    async def execute(self, shared_data) -> ActivityResult:
        """Base execute method that should be overridden by activities."""
        raise NotImplementedError("Activities must implement execute method")


def skill_required(skill_name: str):
    """Decorator to specify required skills for methods."""

    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(self, *args, **kwargs):
            if not hasattr(self, "required_skills"):
                self.required_skills = []
            if skill_name not in self.required_skills:
                self.required_skills.append(skill_name)
            return func(self, *args, **kwargs)

        return wrapper

    return decorator


##### my_digital_being/framework/activity_loader.py #####
import importlib
import logging
import re
from pathlib import Path
from typing import Dict, Type, Any, Optional

logger = logging.getLogger(__name__)


def read_activity_code(activity_name: str) -> Optional[str]:
    """
    Reads the .py file from 'activities/' by the given filename (e.g. 'activity_tweet.py').
    Returns its text content or None if file not found.
    """
    activity_file = Path(__file__).parent.parent / "activities" / activity_name
    if not activity_file.exists():
        logger.warning(f"read_activity_code: File not found: {activity_file}")
        return None
    return activity_file.read_text()


def write_activity_code(activity_name: str, new_code: str) -> bool:
    """
    Writes 'new_code' into the .py file in 'activities/' with the given filename.
    Returns True on success, False on error.
    """
    activity_file = Path(__file__).parent.parent / "activities" / activity_name
    try:
        activity_file.write_text(new_code, encoding="utf-8")
        return True
    except Exception as e:
        logger.error(f"write_activity_code: Failed to write {activity_file}: {e}")
        return False


class ActivityLoader:
    def __init__(self, activities_path: str = None, config: dict = None):
        """
        :param activities_path: Where activity_*.py files live.
        :param config: The main config object from being.configs (used to skip disabled).
        """
        if activities_path is None:
            activities_path = Path(__file__).parent.parent / "activities"
        self.activities_path = Path(activities_path)

        # [ADDED] We'll read 'activities_config' from config
        self.activities_config = {}
        if config:
            self.activities_config = config.get("activity_constraints", {}).get(
                "activities_config", {}
            )

        self.loaded_activities: Dict[str, Type[Any]] = {}
        logger.info(f"ActivityLoader initialized with path: {self.activities_path}")

    def load_activities(self):
        """Load all activities from the activities directory."""
        if not self.activities_path.exists():
            logger.error(f"Activities directory not found: {self.activities_path}")
            return

        logger.info(f"Starting to load activities from: {self.activities_path}")
        for activity_file in self.activities_path.glob("activity_*.py"):
            try:
                logger.info(f"Found activity file: {activity_file}")
                file_text = activity_file.read_text()

                # We expect a pattern like: class SomeActivity(ActivityBase):
                class_match = re.search(
                    r"class\s+(\w+)\(.*ActivityBase.*\):", file_text
                )
                if not class_match:
                    logger.error(f"No recognized activity class in {activity_file}")
                    continue

                class_name = class_match.group(1)
                module_name = activity_file.stem  # e.g. "activity_draw"

                # Possibly skip if "enabled": false in activities_config
                activity_cfg = None
                if class_name in self.activities_config:
                    activity_cfg = self.activities_config[class_name]
                elif module_name in self.activities_config:
                    activity_cfg = self.activities_config[module_name]

                if activity_cfg and (activity_cfg.get("enabled") is False):
                    logger.info(
                        f"Activity {class_name} is disabled by config, skipping load."
                    )
                    continue

                spec = importlib.util.spec_from_file_location(
                    module_name, activity_file
                )
                if spec and spec.loader:
                    module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(module)

                    activity_class = getattr(module, class_name)
                    self.loaded_activities[module_name] = activity_class
                    logger.info(
                        f"Successfully loaded activity {module_name} -> class {class_name}"
                    )

            except Exception as e:
                logger.error(
                    f"Failed to load activity {activity_file}: {str(e)}", exc_info=True
                )

    def get_activity(self, activity_name: str) -> Optional[Type[Any]]:
        """Get an activity class by module name (e.g. 'activity_tweet')."""
        return self.loaded_activities.get(activity_name)

    def get_all_activities(self) -> Dict[str, Type[Any]]:
        """Get all loaded activities (module_name -> class)."""
        return self.loaded_activities.copy()

    def reload_activities(self):
        """Reload all activities by clearing and reloading."""
        self.loaded_activities.clear()
        self.load_activities()


##### my_digital_being/framework/activity_selector.py #####
import logging
import random
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class ActivitySelector:
    def __init__(self, constraints: Dict[str, Any], state):
        """
        :param constraints: A dictionary that typically includes:
            {
              "activity_cooldowns": { ... },  # No longer used
              "activity_requirements": { ... },
              "activities_config": { "DrawActivity": {"enabled": false}, ... }
            }
        :param state: The DigitalBeing's State object, used to check mood, energy, etc.
        """
        self.constraints = constraints
        self.state = state

        # Tracks the last time each activity class was executed
        self.last_activity_times: Dict[str, datetime] = {}

        # The loader is not set until set_activity_loader() is called
        self.activity_loader = None

    def set_activity_loader(self, loader):
        """
        Attach an ActivityLoader instance to this ActivitySelector.
        That loader has the loaded_activities dictionary (module_name -> activity_class).
        """
        self.activity_loader = loader
        logger.info("Activity loader set in selector")

    def select_next_activity(self):
        """
        Main entry point:
        1. Gather all available activities (not on cooldown, not disabled).
        2. Filter them by additional requirements like energy, skill requirements, etc.
        3. Use personality to pick one at random (weighted).
        4. Record the time we picked it.
        5. Return the activity instance or None.
        """
        if not self.activity_loader:
            logger.error("Activity loader not set; cannot select activity.")
            return None

        # Step 1: get all activities that are not on cooldown and are enabled
        available_activities = self._get_available_activities()
        if not available_activities:
            next_available = self.get_next_available_times()
            logger.info(
                f"No activities available at this time. Next available activities: {next_available}"
            )
            return None

        # Step 2: filter out ones that fail "energy" or "activity_requirements"
        suitable_activities = []
        for activity in available_activities:
            activity_name = activity.__class__.__name__
            if self._check_energy_requirements(
                activity
            ) and self._check_activity_requirements(activity_name):
                logger.info(f"Activity {activity_name} is suitable for execution.")
                suitable_activities.append(activity)
            else:
                logger.info(f"Activity {activity_name} does not meet requirements.")

        if not suitable_activities:
            logger.info("No activities suitable for current state.")
            return None

        # Step 3: personality-based selection
        # (If you have a "personality" dict in state, else use {}.)
        personality = self.state.get_current_state().get("personality", {})
        selected_activity = self._select_based_on_personality(
            suitable_activities, personality
        )

        if selected_activity:
            chosen_name = selected_activity.__class__.__name__
            logger.info(f"Selected activity: {chosen_name}")
            # Step 4: record the time we picked it
            self.last_activity_times[chosen_name] = datetime.now()

        return selected_activity

    def get_next_available_times(self) -> List[Dict[str, Any]]:
        """
        Provide info on when each loaded activity class will be available again.
        This is mostly for debugging/logging: "You can next run DrawActivity in 1.5 hours", etc.
        We now use the activity's decorator-based cooldown.
        """
        current_time = datetime.now()
        next_available = []

        all_activities = self.activity_loader.get_all_activities()

        for activity_name, activity_class in all_activities.items():
            base_name = activity_class.__name__

            # Pull cooldown from the class (decorator)
            cooldown = getattr(activity_class, "cooldown", 0)
            last_time = self.last_activity_times.get(base_name)

            if last_time:
                time_since_last = (current_time - last_time).total_seconds()
                time_remaining = max(0, cooldown - time_since_last)
                next_time = current_time + timedelta(seconds=time_remaining)

                next_available.append(
                    {
                        "activity": base_name,
                        "available_in_seconds": time_remaining,
                        "next_available_at": next_time.strftime("%Y-%m-%d %H:%M:%S"),
                        "cooldown_period": cooldown,
                    }
                )
            else:
                # never run before => it's available now
                next_available.append(
                    {
                        "activity": base_name,
                        "available_in_seconds": 0,
                        "next_available_at": "Now",
                        "cooldown_period": cooldown,
                    }
                )

        # sort by soonest availability
        return sorted(next_available, key=lambda x: x["available_in_seconds"])

    def _get_available_activities(self) -> List[Any]:
        """
        Return a list of *activity instances* that:
          1) Are loaded by the ActivityLoader
          2) Are "enabled" in the config
          3) Are not on cooldown (based on the activity's own decorator-based cooldown)
        Then the caller can further filter them for energy or skill requirements.
        """
        available = []
        current_time = datetime.now()

        all_activities = self.activity_loader.get_all_activities()
        activities_config = self.constraints.get("activities_config", {})

        for module_name, activity_class in all_activities.items():
            base_name = activity_class.__name__

            # 1) skip if disabled
            if base_name in activities_config:
                if activities_config[base_name].get("enabled", True) is False:
                    logger.info(f"Skipping disabled activity: {base_name}")
                    continue

            # 2) check if it's on cooldown
            cooldown = getattr(activity_class, "cooldown", 0)
            last_time = self.last_activity_times.get(base_name)
            if last_time:
                time_since_last = (current_time - last_time).total_seconds()
                if time_since_last < cooldown:
                    logger.info(
                        f"{base_name} still on cooldown for {cooldown - time_since_last:.1f}s more."
                    )
                    continue

            # If we get here, the activity is enabled & not on cooldown
            try:
                instance = activity_class()
                logger.info(f"Created instance of {base_name} successfully.")
                available.append(instance)
            except Exception as e:
                logger.error(
                    f"Failed to create instance of {base_name}: {e}", exc_info=True
                )

        return available

    def _check_activity_requirements(self, activity_name: str) -> bool:
        """
        Check constraints['activity_requirements'][activity_name] if you need logic
        for required skills or memory usage. Currently returns True to accept all.
        """
        requirements = self.constraints.get("activity_requirements", {}).get(
            activity_name, {}
        )
        logger.debug(f"Checking requirements for {activity_name}: {requirements}")
        return True

    def _check_energy_requirements(self, activity) -> bool:
        """
        Check if the being has enough energy for the activity (activity.energy_cost).
        """
        current_energy = self.state.get_current_state().get("energy", 1.0)
        required_energy = getattr(activity, "energy_cost", 0.2)
        has_energy = current_energy >= required_energy

        if not has_energy:
            logger.info(
                f"Insufficient energy for {activity.__class__.__name__} "
                f"(required={required_energy}, current={current_energy})."
            )
        return has_energy

    def _select_based_on_personality(
        self, activities: List[Any], personality: Dict[str, float]
    ) -> Optional[Any]:
        """
        Given a list of candidate activity instances, choose one with a weighted random approach.
        """
        if not activities:
            return None

        weights = []
        for activity in activities:
            weight = 1.0
            if hasattr(activity, "creativity_factor"):
                weight *= (
                    1 + personality.get("creativity", 0.5) * activity.creativity_factor
                )
            if hasattr(activity, "social_factor"):
                weight *= (
                    1 + personality.get("friendliness", 0.5) * activity.social_factor
                )
            weights.append(weight)

        chosen = random.choices(activities, weights=weights, k=1)[0]
        return chosen


##### my_digital_being/framework/api_key_setup.py #####
"""Tool for securely setting up API keys."""

import logging
from typing import List, Dict, Tuple
import os
from .secret_storage import secret_manager

logger = logging.getLogger(__name__)


class APIKeySetup:
    """Manages the setup and validation of API keys for skills."""

    @staticmethod
    async def setup_keys(skill_name: str, required_keys: List[str]) -> Dict[str, bool]:
        """
        Set up API keys for a skill using the configured secret storage.

        Args:
            skill_name: Name of the skill requiring API keys
            required_keys: List of required API key names

        Returns:
            Dictionary mapping key names to setup success status
        """
        results = {}

        try:
            # For Replit environment, use ask_secrets
            if "REPL_ID" in os.environ:
                from replit import ask_secrets

                env_keys = [
                    f"{skill_name.upper()}_{key.upper()}_API_KEY"
                    for key in required_keys
                ]

                await ask_secrets(
                    secret_keys=env_keys,
                    user_message=f"""
The {skill_name} skill requires the following API keys to function:
{', '.join(required_keys)}

Please provide these keys to enable the skill's functionality.
These will be stored securely as environment variables.
""",
                )

            # Verify keys were set properly
            for key in required_keys:
                exists = await secret_manager.check_api_key_exists(skill_name, key)
                results[key] = exists

                if exists:
                    logger.info(f"Successfully set up {key} API key for {skill_name}")
                else:
                    logger.warning(f"Failed to set up {key} API key for {skill_name}")

        except Exception as e:
            logger.error(f"Error setting up API keys for {skill_name}: {e}")
            for key in required_keys:
                results[key] = False

        return results

    @staticmethod
    async def check_skill_keys(
        skill_name: str, required_keys: List[str]
    ) -> Tuple[bool, List[str]]:
        """
        Check if a skill has all required API keys configured.

        Args:
            skill_name: Name of the skill to test
            required_keys: List of required API keys

        Returns:
            Tuple of (success, list of missing keys)
        """
        missing_keys = []
        for key in required_keys:
            exists = await secret_manager.check_api_key_exists(skill_name, key)
            if not exists:
                missing_keys.append(key)

        return len(missing_keys) == 0, missing_keys

    @staticmethod
    async def list_skill_requirements(skill_requirements: Dict[str, List[str]]) -> str:
        """
        Get a formatted string of all skills and their API key requirements.

        Args:
            skill_requirements: Dictionary mapping skill names to their required keys

        Returns:
            Formatted string showing all skills and their required API keys
        """
        if not skill_requirements:
            return "No skills with API key requirements registered."

        output = ["Skill API Key Requirements:"]
        for skill, keys in skill_requirements.items():
            success, missing = await APIKeySetup.check_skill_keys(skill, keys)
            status = "✓" if success else "✗"
            output.append(f"\n{status} {skill}:")
            for key in keys:
                exists = await secret_manager.check_api_key_exists(skill, key)
                configured = "✓" if exists else "✗"
                output.append(f"  {configured} {key}")

        return "\n".join(output)


##### my_digital_being/framework/api_management.py #####
"""
Unified API key management system with flexible storage backends.
Implements:
 - get_skill_status -> returns any "required_keys"
 - get_composio_integrations -> calls composio_manager.list_available_integrations()
 - set_api_key -> if you want to store them
"""

import logging
from typing import Dict, Any, Optional, Set, List

from .secret_storage import secret_manager
from .composio_integration import composio_manager

logger = logging.getLogger(__name__)


class APIManager:
    def __init__(self):
        # Example: track required keys for each skill
        self._required_keys: Dict[str, Set[str]] = {}
        self._secret_manager = secret_manager
        self._composio_manager = composio_manager
        logger.info("Initialized API Manager with Composio integration")

    @property
    def composio_manager(self):
        return self._composio_manager

    def register_required_keys(self, skill_name: str, required_keys: List[str]) -> bool:
        """
        Register that a given skill_name requires the specified list of key names (e.g. ["OPENAI"]).
        """
        if not skill_name or not required_keys:
            return False
        self._required_keys[skill_name] = set(required_keys)
        logger.info(f"Registered keys for skill {skill_name}: {required_keys}")
        return True

    def get_required_keys(
        self, skill_name: Optional[str] = None
    ) -> Dict[str, List[str]]:
        """
        Return a dict of skill -> list of required keys.
        If skill_name is provided, return only that one skill's key list.
        """
        if skill_name:
            # Return just one skill's keys if it exists
            if skill_name in self._required_keys:
                return {skill_name: list(self._required_keys[skill_name])}
            else:
                return {skill_name: []}
        else:
            # Return all
            return {skill: list(keys) for skill, keys in self._required_keys.items()}

    async def check_api_key_exists(self, skill_name: str, key_name: str) -> bool:
        """
        Pass-through to secret_manager to check if a key is set.
        This is used in e.g. ImageGenerationSkill or other activities that do:
        `await api_manager.check_api_key_exists(...).`
        """
        return await self._secret_manager.check_api_key_exists(skill_name, key_name)

    async def get_api_key(self, skill_name: str, key_name: str) -> Optional[str]:
        """
        Return the actual API key string from secret_manager.
        Called by skill_chat.py's initialize() or skill_generate_image.py, etc.
        """
        return await self._secret_manager.get_api_key(skill_name, key_name)

    async def get_skill_status(self) -> Dict[str, Any]:
        """
        Example: For each skill, show which keys are configured or not.
        """
        skills_status = {}
        for skill, keys in self._required_keys.items():
            skill_info = {"display_name": skill.title(), "required_keys": {}}
            for k in keys:
                # Check if configured
                exists = await self._secret_manager.check_api_key_exists(skill, k)
                skill_info["required_keys"][k] = bool(exists)
            skills_status[skill] = skill_info
        return skills_status

    async def set_api_key(
        self, skill_name: str, key_name: str, value: str
    ) -> Dict[str, Any]:
        """
        Store a new API key into secret_manager for a given skill & key name.
        """
        success = await self._secret_manager.set_api_key(skill_name, key_name, value)
        return {"success": success, "affected_skills": {}}

    async def get_composio_integrations(self) -> List[Dict[str, Any]]:
        """
        Ask the ComposioManager for the available integrations (connected or not).
        """
        return await self._composio_manager.list_available_integrations()

    async def list_actions_for_app(self, app_name: str) -> Dict[str, Any]:
        """
        Calls composio_manager.list_actions_for_app(app_name).
        """
        return await self._composio_manager.list_actions_for_app(app_name)

    async def get_auth_schemes(self, app_name: str) -> Dict[str, Any]:
        """Get available authentication schemes for an app."""
        return await self._composio_manager.get_auth_schemes(app_name)

    async def initiate_api_key_connection(
        self, app_name: str, api_key: str
    ) -> Dict[str, Any]:
        """Initiate a connection using API key authentication."""
        return await self._composio_manager.initiate_api_key_connection(
            app_name, api_key
        )


# Global
api_manager = APIManager()


##### my_digital_being/framework/composio_integration.py #####
"""
Composio integration module for managing OAuth flows and dynamic tool integration.
Implements:
 - handle_oauth_callback(...) to finalize the connection
 - store a connected indicator in _oauth_connections
 - list_available_integrations() returns "connected": True if we have that.
 - list_actions_for_app(...) returns the app's actions by calling Composio's API directly

[ADDED] We now persist these connections in ./storage/composio_oauth.json
"""

import os
import logging
import json
from pathlib import Path
from typing import Dict, Any, List

import requests  # Used for the direct Composio API call

from .secret_storage import secret_manager
from composio_openai import ComposioToolSet

logger = logging.getLogger(__name__)


class ComposioManager:
    def __init__(self):
        self._toolset = None
        self._entity_id = "MyDigitalBeing"
        self._oauth_connections: Dict[str, Dict[str, Any]] = {}
        self._available_apps: Dict[str, Any] = {}

        # [ADDED] We store the OAuth connections in a JSON file
        self.storage_file = Path("./storage/composio_oauth.json")

        logger.info("Starting Composio integration initialization...")

        # Load persisted OAuth connections if any
        self._load_persistence()

        # Initialize the Composio toolset
        self._initialize_toolset()

    # [ADDED] Load connections from disk
    def _load_persistence(self):
        if self.storage_file.exists():
            try:
                with self.storage_file.open("r", encoding="utf-8") as f:
                    self._oauth_connections = json.load(f)
                logger.info(
                    f"Loaded Composio OAuth connections from {self.storage_file}"
                )
            except Exception as e:
                logger.warning(f"Error loading Composio OAuth file: {e}")
        else:
            logger.info("No existing Composio OAuth file found.")

    # [ADDED] Save connections to disk
    def _save_persistence(self):
        try:
            self.storage_file.parent.mkdir(exist_ok=True)
            with self.storage_file.open("w", encoding="utf-8") as f:
                json.dump(self._oauth_connections, f, indent=2)
            logger.info("Saved Composio OAuth connections to disk.")
        except Exception as e:
            logger.error(f"Failed to save Composio OAuth connections: {e}")

    def _initialize_toolset(self):
        try:
            api_key = os.environ.get("COMPOSIO_API_KEY")
            if not api_key:
                logger.error("No COMPOSIO_API_KEY in environment")
                return
            self._toolset = ComposioToolSet(api_key=api_key, entity_id=self._entity_id)
            logger.info("Created ComposioToolSet instance")

            # Load the list of apps
            tools = self._toolset.get_tools(actions=["COMPOSIO_LIST_APPS"])
            result = self._toolset.execute_action(
                action="COMPOSIO_LIST_APPS", params={}, entity_id=self._entity_id
            )
            success_value = result.get("success") or result.get("successfull")
            if success_value:
                apps_data = result.get("data", {})
                apps_list = apps_data.get("apps", [])
                for app_info in apps_list:
                    key = app_info.get("key", "").upper()
                    if key:
                        self._available_apps[key] = app_info
                logger.info(
                    f"Fetched {len(self._available_apps)} apps from Composio meta-app"
                )
            else:
                logger.warning("COMPOSIO_LIST_APPS action failed.")
        except Exception as e:
            logger.error(f"Error init Composio: {e}", exc_info=True)
            self._available_apps = {}

    def mark_app_connected(self, app_name: str, connection_id: str):
        """Utility to mark an app as connected in our local _oauth_connections dict."""
        upper_app = app_name.upper()
        self._oauth_connections[upper_app] = {
            "connected": True,
            "connection_id": connection_id,
        }
        logger.info(
            f"mark_app_connected: Marked {upper_app} as connected with connection_id={connection_id}"
        )

        # [ADDED] Persist updated connections to disk
        self._save_persistence()

    async def initiate_oauth_flow(
        self, app_name: str, redirect_url: str
    ) -> Dict[str, Any]:
        """Begin an OAuth connection for a given app."""
        if not self._toolset:
            return {"success": False, "error": "Toolset not initialized"}

        try:
            upper_app = app_name.upper()
            app_info = self._available_apps.get(upper_app)
            if not app_info:
                return {"success": False, "error": f"Unknown app: {app_name}"}

            # Check if OAuth is supported
            auth_schemes = self._toolset.get_auth_schemes(app=app_info["key"])
            auth_modes = [scheme.auth_mode for scheme in auth_schemes]
            if "OAUTH2" not in auth_modes and "OAUTH1" not in auth_modes:
                return {
                    "success": False,
                    "error": "OAuth is not supported for this app",
                }

            logger.info(f"Initiating OAuth flow for {app_name}")
            connection_req = self._toolset.initiate_connection(
                redirect_url=redirect_url,
                entity_id=self._entity_id,
                app=app_info["key"],
                auth_scheme=auth_modes[0],
            )

            conn_id = getattr(connection_req, "connectionId", None)
            if not conn_id:
                conn_id = getattr(connection_req, "connectedAccountId", None)
            if not conn_id:
                return {"success": False, "error": "Failed to get connection ID"}

            return {
                "success": True,
                "redirect_url": connection_req.redirectUrl,
                "connection_id": conn_id,
            }
        except Exception as e:
            logger.error(
                f"initiate_oauth_flow error for {app_name}: {e}", exc_info=True
            )
            return {"success": False, "error": str(e)}

    async def handle_oauth_callback(
        self, connection_id: str, code: str
    ) -> Dict[str, Any]:
        """
        Finalize the OAuth flow for a given connection_id using the code from the provider.
        Then store 'connected' in _oauth_connections so our front-end can see that it's connected.
        """
        if not self._toolset:
            return {"success": False, "error": "Toolset not initialized"}

        try:
            result = self._toolset.complete_connection(
                connection_id=connection_id, code=code
            )
            if result.success:
                # Mark as connected
                app_key = result.app.upper() if result.app else "UNKNOWN"
                self.mark_app_connected(app_key, connection_id)
                logger.info(f"handle_oauth_callback: Marked {app_key} as connected.")
            else:
                logger.warning(f"handle_oauth_callback: success=False for {result.app}")

            return {
                "success": result.success,
                "app": result.app,
                "message": (
                    "Connection successful" if result.success else "Connection failed"
                ),
            }
        except Exception as e:
            logger.error(f"Error in handle_oauth_callback: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    def mark_app_connected_without_code(self, app_name: str, connected_account_id: str):
        """
        If Composio doesn't require .complete_connection for some flows
        but returns connectedAccountId in the callback,
        we can directly mark the app as connected.
        """
        self.mark_app_connected(app_name, connected_account_id)

    async def list_available_integrations(self) -> List[Dict[str, Any]]:
        """
        Return a list of all apps from _available_apps,
        with "connected" = True if we've tracked them in _oauth_connections.
        """
        results = []
        for key, info in self._available_apps.items():
            upper_key = key.upper()
            is_connected = False
            if upper_key in self._oauth_connections and self._oauth_connections[
                upper_key
            ].get("connected"):
                is_connected = True

            results.append(
                {
                    "name": upper_key,  # e.g. "TWITTER"
                    "display_name": info.get("name", upper_key),
                    "connected": is_connected,
                    "oauth_supported": True,
                }
            )
        return results

    async def list_actions_for_app(self, app_name: str) -> Dict[str, Any]:
        """
        Returns a structure with all possible Composio actions for the given app_name,
        using a direct GET call to Composio's /api/v2/actions/list/all endpoint.

        Example return structure:
        {
            "success": True,
            "actions": [
                "TWITTER_TWEET_CREATE",
                "TWITTER_DM_SEND",
                ...
            ]
        }
        """
        upper_app = app_name.upper()

        # Check if the app is recognized in our local cache
        if upper_app not in self._available_apps:
            return {
                "success": False,
                "error": f"App '{app_name}' not recognized in _available_apps",
            }
        # Check if the app is connected
        if not self._oauth_connections.get(upper_app, {}).get("connected"):
            return {"success": False, "error": f"App '{app_name}' is not connected yet"}

        api_key = os.environ.get("COMPOSIO_API_KEY")
        if not api_key:
            return {"success": False, "error": "No COMPOSIO_API_KEY set in environment"}

        base_url = "https://backend.composio.dev/api/v2/actions/list/all"
        headers = {"x-api-key": api_key}
        params = {"apps": app_name.lower()}  # Composio expects lowercased

        try:
            resp = requests.get(base_url, headers=headers, params=params, timeout=10)
            if resp.status_code == 200:
                data_json = resp.json()
                items = data_json.get("items", [])
                actions = []
                for item in items:
                    action_key = item.get("actionKey")
                    if action_key:
                        actions.append(action_key)
                    else:
                        display_name = item.get("displayName")
                        if display_name:
                            actions.append(display_name)
                return {"success": True, "actions": actions}
            else:
                logger.error(
                    f"Composio API returned {resp.status_code} for app {app_name}"
                )
                return {
                    "success": False,
                    "error": f"Composio returned status {resp.status_code}",
                }
        except Exception as ex:
            logger.error(
                f"Error retrieving actions for {app_name} from Composio: {ex}",
                exc_info=True,
            )
            return {"success": False, "error": str(ex)}

    async def get_auth_schemes(self, app_name: str) -> Dict[str, Any]:
        """Get available authentication schemes for an app."""
        if not self._toolset:
            return {"success": False, "error": "Toolset not initialized"}

        try:
            upper_app = app_name.upper()
            app_info = self._available_apps.get(upper_app)
            if not app_info:
                return {"success": False, "error": f"Unknown app: {app_name}"}

            auth_schemes = self._toolset.get_auth_schemes(app=app_info["key"])
            auth_modes = [scheme.auth_mode for scheme in auth_schemes]

            # Get API key details if API_KEY auth is available
            api_key_details = None
            if "API_KEY" in auth_modes:
                auth_scheme = self._toolset.get_auth_scheme_for_app(
                    app=app_info["key"], auth_scheme="API_KEY"
                )
                # Get all fields for API_KEY auth
                api_key_details = {
                    "fields": [
                        {
                            "name": field.name,
                            "display_name": field.display_name,
                            "description": field.description,
                            "required": field.required,
                        }
                        for field in auth_scheme.fields
                    ]
                }

            return {
                "success": True,
                "auth_modes": auth_modes,
                "api_key_details": api_key_details,
            }
        except Exception as e:
            logger.error(
                f"Error getting auth schemes for {app_name}: {e}", exc_info=True
            )
            return {"success": False, "error": str(e)}


# Global single instance
composio_manager = ComposioManager()


##### my_digital_being/framework/main.py #####
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional
import asyncio
from datetime import datetime

from .memory import Memory
from .state import State
from .activity_selector import ActivitySelector
from .activity_loader import ActivityLoader
from .shared_data import SharedData
from .activity_decorator import ActivityResult

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DigitalBeing:
    def __init__(self, config_path: Optional[str] = None):
        # Use the config directory relative to this file's location
        if config_path is None:
            config_path = str(Path(__file__).parent.parent / "config")
        self.config_path = Path(config_path)
        self.configs = self._load_configs()
        self.shared_data = SharedData()
        self.memory = Memory()
        self.state = State()
        self.activity_loader = ActivityLoader()
        self.activity_selector = ActivitySelector(
            self.configs.get("activity_constraints", {}), self.state
        )

    def _load_configs(self) -> Dict[str, Any]:
        """Load all configuration files."""
        configs = {}
        config_files = [
            "character_config.json",
            "activity_constraints.json",
            "skills_config.json",
        ]

        for config_file in config_files:
            try:
                with open(self.config_path / config_file, "r", encoding="utf-8") as f:
                    configs[config_file.replace(".json", "")] = json.load(f)
            except Exception as e:
                logger.error(f"Failed to load config {config_file}: {e}")
                configs[config_file.replace(".json", "")] = {}

        return configs

    def initialize(self):
        """Initialize the digital being."""
        logger.info("Initializing digital being...")

        # Load configurations
        self.configs = self._load_configs()
        logger.info("Configurations loaded")

        # Register API key requirements from skills_config
        skills_config = self.configs.get("skills_config", {})
        from framework.api_management import api_manager  # Avoid top-level import loops

        logger.info("Registering API key requirements for skills...")
        for skill_name, maybe_skill_dict in skills_config.items():
            # SKIP STR KEYS LIKE 'default_llm_skill'
            if not isinstance(maybe_skill_dict, dict):
                logger.debug(
                    f"Skipping non-dict skill config: {skill_name} -> {maybe_skill_dict}"
                )
                continue

            if maybe_skill_dict.get("enabled", False):
                required_keys = maybe_skill_dict.get("required_api_keys", [])
                if required_keys:
                    api_manager.register_required_keys(skill_name, required_keys)
                    logger.info(
                        f"Registered API key requirements for {skill_name}: {required_keys}"
                    )

        # Initialize sub-components
        self.memory.initialize()
        self.state.initialize(self.configs.get("character_config", {}))

        # Load activities
        self.activity_loader.load_activities()
        self.shared_data.initialize()

        # Set loader in selector
        self.activity_selector.set_activity_loader(self.activity_loader)

        logger.info("Digital being initialization complete")

    def is_configured(self) -> bool:
        """
        Check if being is 'configured'.
        We look at character_config for 'setup_complete': true
        """
        char_cfg = self.configs.get("character_config", {})
        return bool(char_cfg.get("setup_complete", False))

    async def run(self):
        """
        Main run loop. If not configured, we skip activity selection
        (but keep looping so the server can remain up).
        """
        logger.info("Starting digital being main loop...")

        try:
            while True:
                # If not configured, skip picking an activity
                if not self.is_configured():
                    logger.warning(
                        "Digital Being NOT configured. Skipping activity execution."
                    )
                    await asyncio.sleep(3)
                    continue

                current_activity = self.activity_selector.select_next_activity()
                if current_activity:
                    logger.info(
                        f"Selected activity: {current_activity.__class__.__name__}"
                    )
                    await self.execute_activity(current_activity)

                self.state.update()
                self.memory.persist()
                await asyncio.sleep(1)  # short delay to avoid busy-waiting

        except KeyboardInterrupt:
            logger.info("Shutting down digital being...")
            self.cleanup()

    async def execute_activity(self, activity) -> ActivityResult:
        """Execute a selected activity."""
        try:
            logger.info(
                f"Starting execution of activity: {activity.__class__.__name__}"
            )
            result = await activity.execute(self.shared_data)

            if not isinstance(result, ActivityResult):
                logger.warning(
                    f"Activity {activity.__class__.__name__} did not return an ActivityResult"
                )
                result = ActivityResult(
                    success=bool(result),
                    data=result if result else None,
                    error="Invalid result type" if not result else None,
                )

            # Store the activity result
            activity_record = {
                "timestamp": datetime.now().isoformat(),
                "activity_type": activity.__class__.__name__,
                "result": result.to_dict(),
            }
            self.memory.store_activity_result(activity_record)

            if result.success:
                logger.info(f"Successfully executed: {activity.__class__.__name__}")
                self.state.record_activity_completion()
            else:
                logger.warning(
                    f"Activity returned failure: {activity.__class__.__name__}"
                )

            return result

        except Exception as e:
            error_msg = f"Failed to execute {activity.__class__.__name__}: {e}"
            logger.error(error_msg)

            error_result = ActivityResult(success=False, error=str(e))
            self.memory.store_activity_result(
                {
                    "timestamp": datetime.now().isoformat(),
                    "activity_type": activity.__class__.__name__,
                    "result": error_result.to_dict(),
                }
            )

            return error_result

    def cleanup(self):
        """Cleanup resources before shutdown."""
        self.memory.persist()
        self.state.save()
        logger.info("Cleanup completed")


if __name__ == "__main__":
    import asyncio

    being = DigitalBeing()
    being.initialize()
    asyncio.run(being.run())


##### my_digital_being/framework/memory.py #####
"""Memory management system for storing and retrieving activity history."""

import json
import logging
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime, timezone

logger = logging.getLogger(__name__)


class Memory:
    def __init__(self, storage_path: str = "./storage"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(exist_ok=True)
        self.short_term_memory: List[Dict[str, Any]] = []
        self.long_term_memory: Dict[str, Any] = {}
        self.memory_file = self.storage_path / "memory.json"
        self.initialize()

    def initialize(self):
        """Initialize memory system."""
        self._load_memory()

    def _load_memory(self):
        """Load memory from persistent storage."""
        try:
            if self.memory_file.exists():
                with open(self.memory_file, "r") as f:
                    try:
                        data = json.load(f)
                        if isinstance(data, dict):
                            self.long_term_memory = data.get("long_term", {})
                            self.short_term_memory = data.get("short_term", [])
                        else:
                            logger.warning(
                                "Invalid memory file format, resetting memory"
                            )
                            self.long_term_memory = {}
                            self.short_term_memory = []
                            self.persist()  # Reset the file with proper format
                    except json.JSONDecodeError as je:
                        logger.error(f"Failed to parse memory file: {je}")
                        # Backup corrupted file
                        backup_path = self.memory_file.with_suffix(".json.bak")
                        self.memory_file.rename(backup_path)
                        logger.info(f"Backed up corrupted memory file to {backup_path}")
                        # Reset memory
                        self.long_term_memory = {}
                        self.short_term_memory = []
                        self.persist()  # Create new file with proper format
        except Exception as e:
            logger.error(f"Failed to load memory: {e}")
            self.long_term_memory = {}
            self.short_term_memory = []

    def store_activity_result(self, activity_record: Dict[str, Any]):
        """Store the result of an activity in memory."""
        try:
            # Ensure we have a valid activity record
            if not isinstance(activity_record, dict):
                logger.error("Invalid activity record format")
                return

            # Extract and validate the result
            result = activity_record.get("result", {})
            if isinstance(result, dict):
                # Store standardized activity record with UTC timestamp
                memory_entry = {
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "activity_type": activity_record.get("activity_type", "Unknown"),
                    "success": result.get("success", False),
                    "error": result.get("error"),
                    "data": result.get("data"),
                    "metadata": result.get("metadata", {}),
                }
                self.short_term_memory.append(memory_entry)
                self._consolidate_memory()
                self.persist()  # Persist after each update
                logger.info(
                    f"Stored activity result for {memory_entry['activity_type']}"
                )
            else:
                logger.error(f"Invalid result format in activity record: {result}")

        except Exception as e:
            logger.error(f"Failed to store activity result: {e}")

    def _consolidate_memory(self):
        """Consolidate short-term memory into long-term memory."""
        if len(self.short_term_memory) > 100:  # Keep last 100 activities in short-term
            older_memories = self.short_term_memory[
                :-50
            ]  # Move older ones to long-term
            self.short_term_memory = self.short_term_memory[-50:]

            for memory in older_memories:
                activity_type = memory["activity_type"]
                if activity_type not in self.long_term_memory:
                    self.long_term_memory[activity_type] = []
                self.long_term_memory[activity_type].append(memory)

    def get_recent_activities(
        self, limit: int = 10, offset: int = 0
    ) -> List[Dict[str, Any]]:
        """Get recent activities from memory with success/failure status."""
        # Sort all activities by timestamp in descending order (most recent first)
        all_activities = sorted(
            self.short_term_memory, key=lambda x: x["timestamp"], reverse=True
        )

        # Apply pagination
        paginated_activities = all_activities[offset : offset + limit]

        # Format timestamps for display
        return [
            {
                "timestamp": self._format_timestamp(activity["timestamp"]),
                "activity_type": activity["activity_type"],
                "success": activity["success"],
                "error": activity.get("error"),
                "data": activity.get("data"),
                "metadata": activity.get("metadata", {}),
            }
            for activity in paginated_activities
        ]

    def _format_timestamp(self, timestamp_str: str) -> str:
        """Format ISO timestamp to human-readable format."""
        try:
            dt = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
            return dt.strftime("%Y-%m-%d %H:%M:%S %Z")
        except Exception:
            return timestamp_str

    def get_activity_history(self, activity_type: str) -> List[Dict[str, Any]]:
        """Get history of specific activity type."""
        activities = self.long_term_memory.get(activity_type, [])
        return [
            {**activity, "timestamp": self._format_timestamp(activity["timestamp"])}
            for activity in activities
        ]

    def persist(self):
        """Persist memory to storage."""
        try:
            memory_data = {
                "short_term": self.short_term_memory,
                "long_term": self.long_term_memory,
            }

            # Write to a temporary file first
            temp_file = self.memory_file.with_suffix(".json.tmp")
            with open(temp_file, "w") as f:
                json.dump(memory_data, f, indent=2)

            # Rename temporary file to actual file (atomic operation)
            temp_file.replace(self.memory_file)

        except Exception as e:
            logger.error(f"Failed to persist memory: {e}")

    def clear(self):
        """Clear all memory."""
        self.short_term_memory = []
        self.long_term_memory = {}
        self.persist()

    def get_activity_count(self) -> int:
        """Get total number of activities in memory."""
        return len(self.short_term_memory) + sum(
            len(activities) for activities in self.long_term_memory.values()
        )

    def get_last_activity_timestamp(self) -> str:
        """Get formatted timestamp of the last activity."""
        if not self.short_term_memory:
            return "No activities recorded"

        last_activity = max(self.short_term_memory, key=lambda x: x["timestamp"])
        return self._format_timestamp(last_activity["timestamp"])


##### my_digital_being/framework/secret_storage.py #####
"""Flexible secret storage system that works across different environments."""

import os
import logging
from typing import Optional, Dict, List
from abc import ABC, abstractmethod
from pathlib import Path
from dotenv import load_dotenv

logger = logging.getLogger(__name__)


class SecretStorageBackend(ABC):
    """Abstract base class for secret storage backends."""

    @abstractmethod
    async def get_secret(self, key: str) -> Optional[str]:
        """Retrieve a secret value by key."""
        pass

    @abstractmethod
    async def set_secret(self, key: str, value: str) -> bool:
        """Store a secret value."""
        pass

    @abstractmethod
    async def list_secrets(self) -> List[str]:
        """List all available secret keys."""
        pass


class EnvFileStorage(SecretStorageBackend):
    """Environment file-based secret storage."""

    def __init__(self, env_path: str = None):
        self.env_path = (
            Path(env_path) if env_path else Path(__file__).parent.parent / ".env"
        )
        load_dotenv(self.env_path)

    async def get_secret(self, key: str) -> Optional[str]:
        """Get secret from .env file."""
        return os.environ.get(key)

    async def set_secret(self, key: str, value: str) -> bool:
        """Set secret in .env file."""
        try:
            # Read existing contents
            env_content = {}
            if self.env_path.exists():
                with open(self.env_path, "r") as f:
                    for line in f:
                        if "=" in line and not line.startswith("#"):
                            k, v = line.strip().split("=", 1)
                            env_content[k] = v

            # Update or add new key
            env_content[key] = value

            # Write back to file
            with open(self.env_path, "w") as f:
                for k, v in env_content.items():
                    f.write(f"{k}={v}\n")

            # Update current environment
            os.environ[key] = value
            return True
        except Exception as e:
            logger.error(f"Error setting secret in .env file: {e}")
            return False

    async def list_secrets(self) -> List[str]:
        """List all secrets from .env file."""
        return [key for key in os.environ.keys() if key.endswith("_API_KEY")]


class ReplitSecretStorage(SecretStorageBackend):
    """Replit-specific secret storage implementation."""

    def __init__(self):
        """Initialize with EnvFileStorage as backup."""
        self.env_storage = EnvFileStorage()

    async def get_secret(self, key: str) -> Optional[str]:
        """Get secret from Replit's secure storage."""
        try:
            if "REPL_ID" in os.environ:
                from replit import db

                return db.get(key) or os.environ.get(key)
            return os.environ.get(key)
        except ImportError:
            logger.warning(
                "Replit module not available, falling back to environment variables"
            )
            return os.environ.get(key)
        except Exception as e:
            logger.error(f"Error getting secret from Replit storage: {e}")
            return os.environ.get(key)

    async def set_secret(self, key: str, value: str) -> bool:
        """Set secret using Replit's secure storage and backup to .env."""
        success = False
        try:
            if "REPL_ID" in os.environ:
                # Update environment variable immediately
                os.environ[key] = value

                # Store in Replit's db
                from replit import db

                db[key] = value
                success = True

            # Always try to update .env file as backup
            env_success = await self.env_storage.set_secret(key, value)
            return success or env_success

        except ImportError:
            logger.warning("Replit module not available, falling back to .env file")
            return await self.env_storage.set_secret(key, value)
        except Exception as e:
            logger.error(f"Error setting secret in Replit storage: {e}")
            return await self.env_storage.set_secret(key, value)

    async def list_secrets(self) -> List[str]:
        """List all secrets from both Replit and environment."""
        try:
            if "REPL_ID" in os.environ:
                from replit import db

                replit_keys = [key for key in db.keys() if key.endswith("_API_KEY")]
                env_keys = [
                    key for key in os.environ.keys() if key.endswith("_API_KEY")
                ]
                return list(set(replit_keys + env_keys))
            return [key for key in os.environ.keys() if key.endswith("_API_KEY")]
        except ImportError:
            return [key for key in os.environ.keys() if key.endswith("_API_KEY")]


class SecretManager:
    """Main interface for secret management."""

    def __init__(self):
        """Initialize with appropriate backend based on environment."""
        if "REPL_ID" in os.environ:
            self.backend = ReplitSecretStorage()
            logger.info("Using Replit secret storage backend")
        else:
            self.backend = EnvFileStorage()
            logger.info("Using .env file secret storage backend")

    async def get_api_key(self, skill_name: str, key_name: str) -> Optional[str]:
        """Get an API key for a specific skill."""
        env_key = f"{skill_name.upper()}_{key_name.upper()}_API_KEY"
        return await self.backend.get_secret(env_key)

    async def set_api_key(self, skill_name: str, key_name: str, value: str) -> bool:
        """Securely store an API key."""
        env_key = f"{skill_name.upper()}_{key_name.upper()}_API_KEY"
        success = await self.backend.set_secret(env_key, value)
        if success:
            # Also set any other skills that use the same key
            try:
                from framework.api_management import api_manager

                all_skills = api_manager.get_required_keys()
                for other_skill, required_keys in all_skills.items():
                    if key_name.upper() in [k.upper() for k in required_keys]:
                        other_env_key = (
                            f"{other_skill.upper()}_{key_name.upper()}_API_KEY"
                        )
                        await self.backend.set_secret(other_env_key, value)
            except Exception as e:
                logger.error(f"Error propagating API key to other skills: {e}")
        return success

    async def check_api_key_exists(self, skill_name: str, key_name: str) -> bool:
        """Check if an API key exists."""
        env_key = f"{skill_name.upper()}_{key_name.upper()}_API_KEY"
        return bool(await self.backend.get_secret(env_key))

    async def list_configured_keys(self) -> Dict[str, List[str]]:
        """Get all configured API keys grouped by skill."""
        secrets = await self.backend.list_secrets()
        configured_keys = {}

        for secret in secrets:
            if secret.endswith("_API_KEY"):
                parts = secret.split("_")
                if len(parts) >= 3:
                    skill_name = parts[0].lower()
                    key_name = "_".join(parts[1:-1]).lower()

                    if skill_name not in configured_keys:
                        configured_keys[skill_name] = []
                    configured_keys[skill_name].append(key_name)

        return configured_keys


# Global instance
secret_manager = SecretManager()


##### my_digital_being/framework/shared_data.py #####
import logging
from typing import Dict, Any
from threading import Lock

logger = logging.getLogger(__name__)


class SharedData:
    """Thread-safe shared data storage for activities and skills."""

    def __init__(self):
        self._data: Dict[str, Any] = {}
        self._locks: Dict[str, Lock] = {}
        self._global_lock = Lock()

    def initialize(self):
        """Initialize shared data storage."""
        with self._global_lock:
            self._data = {"system": {}, "memory": {}, "state": {}, "temp": {}}
            for category in self._data:
                self._locks[category] = Lock()

    def get(self, category: str, key: str, default: Any = None) -> Any:
        """Get a value from shared data."""
        if category not in self._data:
            logger.warning(f"Attempting to access invalid category: {category}")
            return default

        with self._locks[category]:
            return self._data[category].get(key, default)

    def set(self, category: str, key: str, value: Any) -> bool:
        """Set a value in shared data."""
        if category not in self._data:
            logger.warning(f"Attempting to write to invalid category: {category}")
            return False

        with self._locks[category]:
            self._data[category][key] = value
        return True

    def update(self, category: str, updates: Dict[str, Any]) -> bool:
        """Update multiple values in a category."""
        if category not in self._data:
            logger.warning(f"Attempting to update invalid category: {category}")
            return False

        with self._locks[category]:
            self._data[category].update(updates)
        return True

    def delete(self, category: str, key: str) -> bool:
        """Delete a value from shared data."""
        if category not in self._data:
            logger.warning(f"Attempting to delete from invalid category: {category}")
            return False

        with self._locks[category]:
            if key in self._data[category]:
                del self._data[category][key]
                return True
        return False

    def clear_category(self, category: str) -> bool:
        """Clear all data in a category."""
        if category not in self._data:
            logger.warning(f"Attempting to clear invalid category: {category}")
            return False

        with self._locks[category]:
            self._data[category].clear()
        return True

    def get_category_data(self, category: str) -> Dict[str, Any]:
        """Get all data in a category."""
        if category not in self._data:
            logger.warning(f"Attempting to access invalid category: {category}")
            return {}

        with self._locks[category]:
            return self._data[category].copy()

    def exists(self, category: str, key: str) -> bool:
        """Check if a key exists in a category."""
        if category not in self._data:
            return False

        with self._locks[category]:
            return key in self._data[category]


##### my_digital_being/framework/skill_config.py #####
"""Secure skill configuration management system + dynamic Composio skills."""

import os
import logging
from typing import Dict, Any, Optional, Set, List

logger = logging.getLogger(__name__)


class SkillConfig:
    """Manages secure configuration for manually coded skills, including API keys."""

    # Class-level storage for tracking API key requirements
    _required_keys: Dict[str, Set[str]] = {}
    _initialized_skills: Set[str] = set()

    def __init__(self, skill_name: str):
        """Initialize skill configuration."""
        self.skill_name = skill_name
        self.config: Dict[str, Any] = {}
        self._load_config()

        if skill_name not in SkillConfig._initialized_skills:
            SkillConfig._initialized_skills.add(skill_name)

    def _load_config(self):
        """Load configuration from environment variables."""
        prefix = f"{self.skill_name.upper()}_"
        for key, value in os.environ.items():
            if key.startswith(prefix):
                config_key = key[len(prefix) :].lower()
                self.config[config_key] = value

    def get_api_key(self, key_name: str) -> Optional[str]:
        """
        Safely retrieve an API key from environment variables.
        Raises ValueError if the key is required but not found.
        """
        env_key = f"{self.skill_name.upper()}_{key_name.upper()}_API_KEY"
        api_key = os.environ.get(env_key)

        if not api_key and self._is_key_required(key_name):
            error_msg = (
                f"Required API key '{key_name}' not found for skill '{self.skill_name}'"
            )
            logger.error(error_msg)
            raise ValueError(error_msg)

        return api_key

    def get_config(self, key: str, default: Any = None) -> Any:
        """Get a configuration value."""
        return self.config.get(key, default)

    def _is_key_required(self, key_name: str) -> bool:
        """Check if an API key is required for this skill."""
        return (
            self.skill_name in SkillConfig._required_keys
            and key_name in SkillConfig._required_keys[self.skill_name]
        )

    @classmethod
    def register_required_keys(cls, skill_name: str, required_keys: List[str]) -> bool:
        """Register required API keys for a manually-coded skill."""
        cls._required_keys[skill_name] = set(required_keys)
        missing_keys = []
        for key in required_keys:
            env_key = f"{skill_name.upper()}_{key.upper()}_API_KEY"
            if not os.environ.get(env_key):
                missing_keys.append(key)
        if missing_keys:
            logger.error(
                f"Missing required API keys for {skill_name}: {', '.join(missing_keys)}"
            )
            return False
        return True

    @classmethod
    def get_required_keys(cls, skill_name: str = None) -> Dict[str, Set[str]]:
        """Get all required API keys, optionally filtered by skill."""
        if skill_name:
            return {skill_name: cls._required_keys.get(skill_name, set())}
        return cls._required_keys.copy()

    @classmethod
    def verify_skill_keys(cls, skill_name: str) -> tuple[bool, list[str]]:
        """Verify that all required API keys for a skill are available."""
        if skill_name not in cls._required_keys:
            return True, []
        missing_keys = []
        for key in cls._required_keys[skill_name]:
            env_key = f"{skill_name.upper()}_{key.upper()}_API_KEY"
            if not os.environ.get(env_key):
                missing_keys.append(key)
        return len(missing_keys) == 0, missing_keys


#
# BELOW: Our new “DynamicComposioSkills” helper for storing discovered actions as if they were skills
#


class DynamicComposioSkills:
    """
    A registry for "dynamic" skill records discovered from Composio apps/actions.
    Each record might look like:
        {
          "skill_name": "composio_twitter_twitter_tweet_create",
          "enabled": True,
          "required_api_keys": ["COMPOSIO"],   # for example
          "metadata": {
             "composio_app": "TWITTER",
             "composio_action": "TWITTER_TWEET_CREATE"
          }
        }
    """

    # In-memory storage of these dynamic skills
    _dynamic_skills: List[Dict[str, Any]] = []

    @classmethod
    def register_composio_actions(cls, app_name: str, actions: List[str]):
        """
        For each action in `actions`, create a dynamic skill record and store it in _dynamic_skills.
        e.g. skill_name = "composio_{app_name}_{action_id}" (all lowercase)
        """
        for action_id in actions:
            skill_name = f"composio_{app_name.lower()}_{action_id.lower()}"
            skill_record = {
                "skill_name": skill_name,
                "enabled": True,
                # You could decide "required_api_keys": ["COMPOSIO"] or none at all
                "required_api_keys": ["COMPOSIO"],
                "metadata": {
                    "composio_app": app_name.upper(),
                    "composio_action": action_id,
                },
            }

            # Avoid duplicates if the user calls this multiple times
            if not any(s for s in cls._dynamic_skills if s["skill_name"] == skill_name):
                cls._dynamic_skills.append(skill_record)
                logger.info(f"[DynamicComposioSkills] Registered {skill_name}")

    @classmethod
    def get_all_dynamic_skills(cls) -> List[Dict[str, Any]]:
        """Return the entire list of dynamic Composio-based skill records."""
        return cls._dynamic_skills.copy()

    @classmethod
    def find_skill_by_name(cls, skill_name: str) -> Optional[Dict[str, Any]]:
        """Look up a single dynamic skill record by name."""
        for skill in cls._dynamic_skills:
            if skill["skill_name"] == skill_name:
                return skill
        return None


##### my_digital_being/framework/state.py #####
import json
import logging
from pathlib import Path
from typing import Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class State:
    def __init__(self, state_path: str = "./storage"):
        self.state_path = Path(state_path)
        self.state_path.mkdir(exist_ok=True)
        self.state_file = self.state_path / "state.json"
        self.current_state: Dict[str, Any] = {
            "mood": "neutral",
            "energy": 1.0,
            "last_activity_timestamp": None,
            "active_tasks": [],
            "personality": {},
        }

    def initialize(self, character_config: Dict[str, Any]):
        """Initialize state with character configuration."""
        self._load_state()
        self.current_state["personality"] = character_config.get("personality", {})
        self.save()

    def _load_state(self):
        """Load state from persistent storage."""
        try:
            if self.state_file.exists():
                with open(self.state_file, "r") as f:
                    self.current_state = json.load(f)
        except Exception as e:
            logger.error(f"Failed to load state: {e}")

    def update(self):
        """Update state based on current conditions."""
        current_time = datetime.now()

        # Update energy levels
        if self.current_state["last_activity_timestamp"]:
            last_activity = datetime.fromisoformat(
                self.current_state["last_activity_timestamp"]
            )
            time_diff = (current_time - last_activity).total_seconds()
            self.current_state["energy"] = min(
                1.0, self.current_state["energy"] + (time_diff / 3600) * 0.1
            )

        # Only update timestamp if there was a successful activity completion
        if hasattr(self, "_last_completed_activity"):
            self.current_state["last_activity_timestamp"] = current_time.isoformat()
            delattr(self, "_last_completed_activity")

        self.save()

    def get_current_state(self) -> Dict[str, Any]:
        """Get current state."""
        return self.current_state.copy()

    def update_mood(self, new_mood: str):
        """Update the current mood."""
        self.current_state["mood"] = new_mood
        self.save()

    def consume_energy(self, amount: float):
        """Consume energy for an activity."""
        self.current_state["energy"] = max(0.0, self.current_state["energy"] - amount)
        self.save()

    def record_activity_completion(self):
        """Mark that an activity was completed successfully."""
        self._last_completed_activity = True
        self.save()

    def add_active_task(self, task_id: str):
        """Add an active task."""
        if task_id not in self.current_state["active_tasks"]:
            self.current_state["active_tasks"].append(task_id)
            self.save()

    def remove_active_task(self, task_id: str):
        """Remove an active task."""
        if task_id in self.current_state["active_tasks"]:
            self.current_state["active_tasks"].remove(task_id)
            self.save()

    def save(self):
        """Save current state to persistent storage."""
        try:
            with open(self.state_file, "w") as f:
                json.dump(self.current_state, f, indent=2)
        except Exception as e:
            logger.error(f"Failed to save state: {e}")


##### my_digital_being/skills/skill_arxiv.py #####
"""
ArXiv Search Skill
Uses arxiv package to search for academic papers on arxiv.org.
No API keys required.
"""

import logging
from typing import List, Dict, Any, Optional
import arxiv
from framework.api_management import api_manager

logger = logging.getLogger(__name__)


class ArxivSkill:
    """
    Skill for searching academic papers on arXiv using the arxiv package.
    No API key required.
    """

    def __init__(self):
        self.skill_name = "arxiv_search"
        self.client = arxiv.Client()
        # Register with api_manager for consistency, though no keys needed
        api_manager.register_required_keys(self.skill_name, [])

    async def search_papers(
        self,
        query: str,
        max_results: int = 5,
        category: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """
        Search for papers on arXiv based on query and parameters.

        Args:
            query: Search query string
            max_results: Maximum number of results to return
            category: Optional arXiv category (e.g., 'cs.AI', 'physics', etc.)

        Returns:
            List of papers with their details
        """
        try:
            # Construct the search query
            full_query = query
            if category:
                full_query = f"cat:{category} AND {query}"

            # Create search object
            search = arxiv.Search(
                query=full_query,
                max_results=max_results,
                sort_by=arxiv.SortCriterion.SubmittedDate,
                sort_order=arxiv.SortOrder.Descending
            )

            # Execute search
            results = list(self.client.results(search))
            
            # Format results
            papers = []
            for paper in results:
                papers.append({
                    "title": paper.title,
                    "authors": [author.name for author in paper.authors],
                    "summary": paper.summary,
                    "published": paper.published.isoformat(),
                    "updated": paper.updated.isoformat(),
                    "doi": paper.doi,
                    "primary_category": paper.primary_category,
                    "categories": paper.categories,
                    "links": [link.href for link in paper.links],
                    "pdf_url": paper.pdf_url,
                })

            logger.info(f"Successfully found {len(papers)} papers matching query: {query}")
            return papers

        except Exception as e:
            logger.error(f"Error searching arXiv: {e}", exc_info=True)
            return [] 
        

##### my_digital_being/skills/skill_chat.py #####
"""
LiteLLM-based Chat Skill that:
 - fetches user-provided key from secret manager
 - passes api_key=... to litellm
 - does NOT set any environment variable
"""

import logging
from typing import Optional, Dict, Any

from litellm import completion
from framework.api_management import api_manager
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)


class ChatSkill:
    """Skill for chat/completion using LiteLLM with a user-provided key, if any."""

    def __init__(self):
        """
        We'll use skill_name = "lite_llm" and required_api_keys = ["LITELLM"].
        That means the key is stored under "LITE_LLM_LITELLM_API_KEY".
        """
        self.skill_name = "lite_llm"
        self.required_api_keys = ["LITELLM"]
        api_manager.register_required_keys(self.skill_name, self.required_api_keys)

        self._initialized = False
        self.model_name: Optional[str] = None
        self._provided_api_key: Optional[str] = None

    async def initialize(self) -> bool:
        """
        1) Load skill config from being.configs["skills_config"]["lite_llm"]["model_name"].
        2) Retrieve the user-provided key from secret manager as "LITELLM".
        3) Store them into instance variables. 
        """
        try:
            # Load the config from the being
            being = DigitalBeing()
            being.initialize()
            skill_cfg = being.configs.get("skills_config", {}).get("lite_llm", {})

            # e.g. "openai/gpt-4", "anthropic/claude-2", etc.
            self.model_name = skill_cfg.get("model_name", "openai/gpt-4o")
            logger.info(f"LiteLLM skill using model = {self.model_name}")

            # Retrieve the user's key from secret manager
            api_key = await api_manager.get_api_key(self.skill_name, "LITELLM")
            if api_key:
                logger.info("Found a user-provided LiteLLM key.")
                self._provided_api_key = api_key
            else:
                logger.info("No LITELLM key found; user might be using no-auth or external provider.")

            self._initialized = True
            return True

        except Exception as e:
            logger.error(f"Failed to initialize LiteLLM skill: {e}", exc_info=True)
            self._initialized = False
            return False

    async def get_chat_completion(
        self,
        prompt: str,
        system_prompt: str = "You are a helpful AI assistant.",
        max_tokens: int = 150,
    ) -> Dict[str, Any]:
        """
        Use litellm.completion() with model=self.model_name, 
        and pass api_key=self._provided_api_key if we have it.
        """
        if not self._initialized:
            return {
                "success": False,
                "error": "LiteLLM skill not initialized",
                "data": None,
            }

        try:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})

            # Just pass the user-provided key, if any:
            response = completion(
                model=self.model_name,
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.7,
                api_key=self._provided_api_key,  # <--- important
            )

            choices = response.get("choices", [])
            if not choices:
                return {
                    "success": False,
                    "error": "No choices returned from LiteLLM",
                    "data": None,
                }

            content = choices[0].get("message", {}).get("content", "")
            finish_reason = choices[0].get("finish_reason", "")
            used_model = response.get("model", self.model_name)

            return {
                "success": True,
                "data": {
                    "content": content,
                    "finish_reason": finish_reason,
                    "model": used_model,
                },
                "error": None,
            }

        except Exception as e:
            logger.error(f"Error in LiteLLM chat completion: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "data": None,
            }


# Global instance
chat_skill = ChatSkill()


##### my_digital_being/skills/skill_generate_image.py #####
"""Image generation skill implementation."""

import logging
from typing import Dict, Any, Tuple
import random
import os
import openai
from openai import OpenAI
import asyncio
from framework.api_management import api_manager

logger = logging.getLogger(__name__)


class ImageGenerationSkill:
    def __init__(self, config: Dict[str, Any]):
        """Initialize the image generation skill with secure API key handling."""
        self.enabled = config.get("enabled", False)
        self.max_generations = config.get("max_generations_per_day", 50)
        self.supported_formats = config.get("supported_formats", ["png", "jpg"])
        self.generations_count = 0

        # Register required API keys
        api_manager.register_required_keys("image_generation", ["OPENAI"])

    async def can_generate(self) -> bool:
        """Check if image generation is allowed."""
        if not self.enabled:
            logger.warning("Image generation is disabled")
            return False

        if self.generations_count >= self.max_generations:
            logger.warning("Daily generation limit reached")
            return False

        # Verify API key exists and is configured
        api_key = await api_manager.check_api_key_exists("image_generation", "OPENAI")
        if not api_key:
            logger.error("OpenAI API key not configured for image generation")
            return False

        return True

    async def generate_image(
        self, prompt: str, size: Tuple[int, int] = (1024, 1024), format: str = "png"
    ) -> Dict[str, Any]:
        """Generate an image based on the prompt."""
        if not await self.can_generate():
            error_msg = "Image generation is not available (disabled, limit reached, or not configured)"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}

        if format not in self.supported_formats:
            error_msg = f"Unsupported format. Use: {self.supported_formats}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}

        try:
            # Get API key from api_manager
            api_key = await api_manager.get_api_key("image_generation", "OPENAI")
            if not api_key:
                error_msg = "OpenAI API key not configured"
                logger.error(error_msg)
                return {"success": False, "error": error_msg}

            # Configure OpenAI with the retrieved API key
            os.environ["OPENAI_API_KEY"] = api_key

            client = OpenAI()

            # Map the size tuple to OpenAI's expected string format
            size_str = f"{size[0]}x{size[1]}"

            logger.info(f"Generating image for prompt: {prompt} with size {size_str}")

            # As OpenAI's library is synchronous, run it in a separate thread to avoid blocking
            loop = asyncio.get_event_loop()
            print(prompt)
            print(size_str)
            response = await loop.run_in_executor(
                None,
                lambda: client.images.generate(
                    model="dall-e-3",
                    prompt=prompt,
                    n=1,
                    size=size_str,
                    response_format="url",  # You can change to "b64_json" if needed
                ),
            )

            # Extract the image URL from the response
            image_url = response.data[0].url

            # Increment counter only on successful generation
            self.generations_count += 1

            # Generate a seed and generation_id for consistency with previous structure
            seed = random.randint(1000, 9999)
            generation_id = f"gen_{self.generations_count}"

            image_data = {
                "width": size[0],
                "height": size[1],
                "format": format,
                "seed": seed,
                "generation_id": generation_id,
                "url": image_url,  # Including the actual image URL from OpenAI
            }

            return {
                "success": True,
                "image_data": image_data,
                "metadata": {
                    "prompt": prompt,
                    "generation_number": self.generations_count,
                },
            }


        except Exception as e:
            logger.error(f"Failed to generate image: {e}")
            return {"success": False, "error": str(e)}

    def reset_counts(self):
        """Reset the generation counter."""
        self.generations_count = 0


##### my_digital_being/skills/skill_web_search.py #####
"""
Tavily-based Web Search Skill that:
 - fetches user-provided key from secret manager
 - passes api_key to TavilyClient
 - provides web search capabilities optimized for RAG
"""

import logging
from typing import Optional, Dict, Any
from tavily import TavilyClient
from framework.api_management import api_manager
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)


class WebSearchSkill:
    """Skill for web search using Tavily with a user-provided key."""

    def __init__(self):
        """
        We'll use skill_name = "web_search" and required_api_keys = ["TAVILY"].
        That means the key is stored under "WEB_SEARCH_TAVILY_API_KEY".
        """
        self.skill_name = "web_search"
        self.required_api_keys = ["TAVILY"]
        api_manager.register_required_keys(self.skill_name, self.required_api_keys)

        self._initialized = False
        self._client: Optional[TavilyClient] = None
        self.search_depth: str = "basic"
        self.default_topic: str = "general"
        self.default_max_tokens: int = 8000

    async def initialize(self) -> bool:
        """
        1) Load skill config from being.configs["skills_config"]["web_search"]
        2) Retrieve the user-provided key from secret manager as "TAVILY".
        3) Initialize TavilyClient with the key.
        """
        try:
            # Load the config from the being
            being = DigitalBeing()
            being.initialize()
            skill_cfg = being.configs.get("skills_config", {}).get("web_search", {})

            # Load configuration with defaults
            self.search_depth = skill_cfg.get("search_depth", "basic")
            self.default_topic = skill_cfg.get("default_topic", "general")
            self.default_max_tokens = skill_cfg.get("max_tokens", 8000)
            
            logger.info(f"Web search skill using search_depth={self.search_depth}, default_topic={self.default_topic}")

            # Retrieve the user's key from secret manager
            api_key = await api_manager.get_api_key(self.skill_name, "TAVILY")
            if not api_key:
                logger.error("No TAVILY API key found")
                return False

            # Initialize the Tavily client
            self._client = TavilyClient(api_key=api_key)
            logger.info("Successfully initialized Tavily client")

            self._initialized = True
            return True

        except Exception as e:
            logger.error(f"Failed to initialize Web search skill: {e}", exc_info=True)
            self._initialized = False
            return False

    async def search(
        self,
        query: str,
        search_depth: Optional[str] = None,
        topic: Optional[str] = None,
        time_range: Optional[str] = None,
        max_tokens: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        Perform a web search using Tavily and return context suitable for RAG applications.

        Args:
            query: The search query
            search_depth: "basic" or "advanced" search depth (defaults to configured value)
            topic: The category of the search (defaults to configured value)
            time_range: Time range filter for the search (e.g., "day", "week", "month", "year")
            max_tokens: Maximum number of tokens to return in the context (defaults to configured value)

        Returns:
            Dictionary containing search context and metadata
        """
        if not self._initialized:
            return {
                "success": False,
                "error": "Web search skill not initialized",
                "data": None,
            }

        try:
            # Use configured defaults if parameters not provided
            search_depth = search_depth or self.search_depth
            topic = topic or self.default_topic
            max_tokens = max_tokens or self.default_max_tokens

            # Get search context optimized for RAG
            context = self._client.get_search_context(
                query=query,
                search_depth=search_depth,
                topic=topic,
                time_range=time_range,
                max_tokens=max_tokens
            )

            return {
                "success": True,
                "data": {
                    "query": query,
                    "context": context,
                    "used_config": {
                        "search_depth": search_depth,
                        "topic": topic,
                        "max_tokens": max_tokens
                    }
                },
                "error": None,
            }

        except Exception as e:
            logger.error(f"Error in Web search: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "data": None,
            }


# Global instance
web_search_skill = WebSearchSkill() 

##### my_digital_being/tools/onboard.py #####
import json
import logging
import asyncio
from pathlib import Path

# We'll need to call api_manager in a synchronous context
from framework.api_management import api_manager
from framework.activity_loader import ActivityLoader

# Adjust these if your config is stored differently:
CHARACTER_CONFIG_FILE = Path(__file__).parent.parent / "config" / "character_config.json"
SKILLS_CONFIG_FILE = Path(__file__).parent.parent / "config" / "skills_config.json"
ACTIVITY_CONSTRAINTS_FILE = Path(__file__).parent.parent / "config" / "activity_constraints.json"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_json_config(path: Path) -> dict:
    """Helper to safely load JSON config from a file."""
    if not path.exists():
        return {}
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Failed to load {path.name}: {e}")
        return {}

def save_json_config(path: Path, data: dict) -> None:
    """Helper to save JSON config atomically."""
    temp_file = path.with_suffix('.tmp')
    try:
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)
        temp_file.replace(path)
    except Exception as e:
        logger.error(f"Failed to save {path.name}: {e}")

def prompt_user(prompt_text: str, default: str = None) -> str:
    """Prompt user for input with an optional default."""
    if default is not None:
        user_input = input(f"{prompt_text} [{default}]: ").strip()
        return user_input if user_input else default
    else:
        return input(f"{prompt_text}: ").strip()

def prompt_yes_no(question: str, default: str = "yes") -> bool:
    """
    Prompt user for a yes/no answer with a default.
    Returns True if 'yes', False if 'no'.
    """
    yes_answers = ["yes", "y"]
    no_answers = ["no", "n"]

    if default.lower() in yes_answers:
        prompt_str = f"{question} [Y/n]: "
    else:
        prompt_str = f"{question} [y/N]: "

    while True:
        choice = input(prompt_str).strip().lower()
        if choice == "" and default:
            choice = default.lower()
        if choice in yes_answers:
            return True
        if choice in no_answers:
            return False
        print("Please respond with 'y' or 'n'.")


#
# Helper to set an API key synchronously by calling the async function
#
def set_api_key_sync(skill_name: str, key_name: str, value: str) -> bool:
    """Call api_manager.set_api_key(...) in a blocking manner for CLI convenience."""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(api_manager.set_api_key(skill_name, key_name, value))
        loop.close()
        return bool(result.get("success", False))
    except Exception as e:
        logger.error(f"Error setting API key for {skill_name} -> {key_name}: {e}")
        return False

def configure_litellm(skills_config: dict) -> None:
    """
    Prompt user to configure a 'lite_llm' skill or skip.
    We allow a custom model_name (like 'anthropic/claude-3', 'openrouter/openai/gpt-4', etc.)
    If the user provides an API key, we store it via secret manager, not in skills_config.
    """
    print("\n--- LiteLLM Configuration ---")
    if prompt_yes_no("Would you like to configure LiteLLM (supports Anthropic, OpenAI, XAI, OpenRouter, etc.)?", "yes"):
        if "lite_llm" not in skills_config:
            skills_config["lite_llm"] = {
                "enabled": True,
                "required_api_keys": ["LITELLM"],  # We'll define "LITELLM" as the key name
                "api_key_mapping": {
                    "LITELLM": "LITELLM_API_KEY"
                },
                "model_name": None
            }
        else:
            # Ensure it's enabled
            skills_config["lite_llm"]["enabled"] = True
            rkeys = skills_config["lite_llm"].setdefault("required_api_keys", [])
            if "LITELLM" not in rkeys:
                rkeys.append("LITELLM")
            amap = skills_config["lite_llm"].setdefault("api_key_mapping", {})
            if "LITELLM" not in amap:
                amap["LITELLM"] = "LITELLM_API_KEY"

        model_name = prompt_user("Enter model name (e.g. 'anthropic/claude-3' or 'openrouter/openai/gpt-4')", "openai/gpt-4o")
        skills_config["lite_llm"]["model_name"] = model_name

        if prompt_yes_no("Do you want to provide an API key now?", "no"):
            the_key = prompt_user("Enter your LiteLLM-supported API key (or skip)", "")
            if the_key:
                success = set_api_key_sync("lite_llm", "LITELLM", the_key)
                if success:
                    print("LiteLLM API key stored securely!")
                else:
                    print("Failed to store LiteLLM API key. Check logs.")

        use_as_default = prompt_yes_no("Use this lite_llm skill as your default LLM for code generation?", "yes")
        if use_as_default:
            skills_config["default_llm_skill"] = "lite_llm"
    else:
        print("Skipping LiteLLM setup. You can still configure another LLM skill or skip LLM altogether.")

def configure_openai_chat(skills_config: dict) -> None:
    """
    Prompt user to configure openai_chat skill (like GPT).
    If the user provides an API key, we store it in secret manager, not in skills_config.
    """
    print("\n--- OpenAI Chat Configuration ---")
    if "openai_chat" not in skills_config:
        skills_config["openai_chat"] = {
            "enabled": True,
            "required_api_keys": ["OPENAI"],
            "api_key_mapping": {"OPENAI": "OPENAI_API_KEY"}
        }
    else:
        skills_config["openai_chat"]["enabled"] = True

    openai_key = prompt_user("Enter your OPENAI_API_KEY (leave blank if stored in .env or skipping)", "")
    if openai_key:
        success = set_api_key_sync("openai_chat", "OPENAI", openai_key)
        if success:
            print("OpenAI API key stored securely!")
        else:
            print("Failed to store OpenAI key. Check logs.")

    if prompt_yes_no("Use openai_chat as the default LLM skill for code generation?", "no"):
        skills_config["default_llm_skill"] = "openai_chat"

def configure_primary_llm(skills_config: dict) -> None:
    """
    Let user pick from:
    1) LiteLLM skill
    2) OpenAI Chat skill
    3) No LLM
    """
    print("\n--- Primary LLM Choice ---")
    print("1) LiteLLM (anthropic, openai, openrouter, etc.)")
    print("2) OpenAI Chat skill only")
    print("3) None / Skip LLM entirely")

    choice = prompt_user("Enter 1, 2, or 3", default="1")
    if choice == "1":
        configure_litellm(skills_config)
    elif choice == "2":
        configure_openai_chat(skills_config)
    else:
        print("Skipping LLM entirely. No GPT-based code generation or advanced tasks.")
        if "default_llm_skill" in skills_config:
            del skills_config["default_llm_skill"]

def configure_character_basics(character_config: dict) -> None:
    print("\n--- Character Basic Setup ---")
    current_name = character_config.get("name", "Digital Being")
    new_name = prompt_user("Character Name", default=current_name)
    character_config["name"] = new_name

    current_objective = character_config.get("objectives", {}).get("primary", "Assist users")
    new_objective = prompt_user("Primary Objective", default=current_objective)

    if "objectives" not in character_config:
        character_config["objectives"] = {}
    character_config["objectives"]["primary"] = new_objective

def configure_advanced_text(character_config: dict, activity_constraints: dict) -> None:
    if prompt_yes_no("Would you like to define advanced objective text / constraints / examples?", "no"):
        print("\n--- Advanced Objectives ---")
        lines = []
        first_line = prompt_user("Enter multi-line advanced objectives. Press Enter on blank line to finish:", "")
        if first_line.strip():
            lines.append(first_line)
        while True:
            line = input()
            if not line.strip():
                break
            lines.append(line)
        combined = "\n".join(lines)
        if combined:
            character_config.setdefault("objectives", {})
            character_config["objectives"]["advanced"] = combined

        print("\n--- Example Activities ---")
        lines2 = []
        first_line = prompt_user("Enter multi-line example activities. Press Enter on blank line to finish:", "")
        if first_line.strip():
            lines2.append(first_line)
        while True:
            line = input()
            if not line.strip():
                break
            lines2.append(line)
        combined2 = "\n".join(lines2)
        if combined2:
            character_config["example_activities"] = combined2

        print("\n--- General Constraints ---")
        lines3 = []
        first_line = prompt_user("Enter multi-line constraints. Press Enter on blank line to finish:", "")
        if first_line.strip():
            lines3.append(first_line)
        while True:
            line = input()
            if not line.strip():
                break
            lines3.append(line)
        combined3 = "\n".join(lines3)
        if combined3:
            activity_constraints["global_constraints"] = combined3

def configure_other_skills(skills_config: dict) -> None:
    print("\n--- Additional Skills ---")
    skill_names = sorted(skills_config.keys())
    for skill_name in skill_names:
        if skill_name in ["openai_chat", "lite_llm", "default_llm_skill"]:
            continue
        skill_data = skills_config[skill_name]
        is_enabled = skill_data.get("enabled", False)
        user_enable = prompt_yes_no(f"Enable skill '{skill_name}'?", "yes" if is_enabled else "no")
        skill_data["enabled"] = user_enable

        if user_enable and skill_data.get("required_api_keys"):
            for required_key in skill_data["required_api_keys"]:
                env_key = skill_data.get("api_key_mapping", {}).get(required_key, f"{skill_name.upper()}_{required_key}")
                val = prompt_user(f"Enter value for {env_key} (leave blank to skip)", "")
                if val:
                    success = set_api_key_sync(skill_name, required_key, val)
                    if success:
                        print(f"API key for {skill_name}:{required_key} stored!")
                    else:
                        print(f"Failed to store API key for {skill_name}:{required_key}")

# [ADDED] Let user pick which activities to enable/disable (CLI approach)
def configure_activities_cli(activities_config: dict) -> None:
    """
    We discover the available activity classes from the ActivityLoader and let the user
    choose which to enable. We store "enabled": bool in the final JSON under activities_config.
    """
    print("\n--- Activity Enable/Disable Setup (CLI) ---")
    loader = ActivityLoader()
    loader.load_activities()
    found_activities = loader.get_all_activities()  # e.g. {"activity_draw": DrawActivity, ...}

    for mod_name, cls in found_activities.items():
        class_name = cls.__name__  # e.g. "DrawActivity"
        # If we already have an entry, use it; otherwise default to True
        current_enabled = activities_config.get(class_name, {}).get("enabled", True)
        user_enable = prompt_yes_no(f"Enable activity '{class_name}'?", "yes" if current_enabled else "no")

        if class_name not in activities_config:
            activities_config[class_name] = {}
        activities_config[class_name]["enabled"] = user_enable


def main():
    print("=========================================================")
    print(" Welcome to the Autonomous Being CLI Onboarding")
    print("=========================================================")

    character_config_path = CHARACTER_CONFIG_FILE
    skills_config_path = SKILLS_CONFIG_FILE
    activity_constraints_path = ACTIVITY_CONSTRAINTS_FILE

    character_config = load_json_config(character_config_path)
    skills_config = load_json_config(skills_config_path)
    activity_constraints = load_json_config(activity_constraints_path)

    # 1) Primary LLM choice
    configure_primary_llm(skills_config)

    # 2) Basic character config
    configure_character_basics(character_config)

    # 3) Advanced text (objectives, examples, constraints)
    configure_advanced_text(character_config, activity_constraints)

    # 4) Other skills
    configure_other_skills(skills_config)

    # [ADDED] 5) Let user pick which activities to enable/disable in CLI
    # If you prefer to do this only in front-end, you can skip this step or remove it.
    if "activities_config" not in activity_constraints:
        activity_constraints["activities_config"] = {}
    configure_activities_cli(activity_constraints["activities_config"])

    # Set setup_complete to true
    character_config["setup_complete"] = True

    # Save updated (without storing any user-provided API keys in JSON)
    print("\nSaving updated JSON configs...")
    save_json_config(character_config_path, character_config)
    save_json_config(skills_config_path, skills_config)
    save_json_config(activity_constraints_path, activity_constraints)

    print("\nOnboarding complete!")
    print("You may now run 'python -m framework.main' or 'python -m server.server' to launch the AI being.")
    print("-----------------------------------------------------------")


if __name__ == "__main__":
    main()


##### my_digital_being/activities/activity_analyze_daily.py #####
# activities/activity_analyze_daily.py

import logging
from typing import Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.memory import Memory
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="AnalyzeDailyActivity",
    energy_cost=0.3,
    cooldown=86400,  # 24 hours
    required_skills=["openai_chat"],
)
class AnalyzeDailyActivity(ActivityBase):
    """
    Activity that reviews the last day's logs from memory and produces a reflection
    or summary, storing that reflection in the memory system for future reference.
    """

    def __init__(self):
        super().__init__()
        self.system_prompt = """You are an AI that helps summarize the events, successes,
        or challenges from the digital being's recent memory. Keep the reflection concise and
        highlight any patterns or potential next steps."""

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting daily analysis of memory...")

            # 1) Initialize the chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize openai_chat skill"
                )

            # 2) Retrieve the last ~10 memory entries for summarization
            memory_obj: Memory = shared_data.get(
                "system", "memory_ref"
            )  # or pass memory another way
            # If not found, fallback to your framework's global memory reference
            if not memory_obj:
                from framework.main import DigitalBeing

                # Fallback to the global being's memory if you prefer
                # In some setups, you can pass it in shared_data, or fetch it from a global reference
                being = DigitalBeing()
                being.initialize()
                memory_obj = being.memory

            recent_activities = memory_obj.get_recent_activities(limit=10, offset=0)

            # 3) Summarize them with the chat skill
            text_snippets = []
            for act in recent_activities:
                snippet = f"- {act['activity_type']}, success={act['success']}, data={act.get('data')}"
                text_snippets.append(snippet)

            combined_text = "\n".join(text_snippets)
            prompt = f"Here are recent logs:\n{combined_text}\n\nProduce a short daily reflection or summary."

            response = await chat_skill.get_chat_completion(
                prompt=prompt, system_prompt=self.system_prompt, max_tokens=150
            )
            if not response["success"]:
                return ActivityResult(success=False, error=response["error"])

            # 4) Return the reflection as success
            reflection = response["data"]["content"]
            return ActivityResult(
                success=True,
                data={"reflection": reflection},
                metadata={
                    "model": response["data"]["model"],
                    "finish_reason": response["data"]["finish_reason"],
                },
            )

        except Exception as e:
            logger.error(f"Error in AnalyzeDailyActivity: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_build_or_update.py #####
import logging
import re
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.activity_loader import write_activity_code
from skills.skill_chat import chat_skill

from framework.skill_config import DynamicComposioSkills
from framework.api_management import api_manager
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)


@activity(
    name="BuildOrUpdateActivity",
    energy_cost=0.6,
    cooldown=172800,  # 2 days
    required_skills=["openai_chat"],
)
class BuildOrUpdateActivity(ActivityBase):
    """
    Activity that takes suggestions from memory, calls an LLM to generate or update
    Python activities, and writes them to the 'activities/' directory.

    We make two calls to the openai_chat skill:
      1) Get a short filename (activity_*.py).
      2) Generate the actual code snippet, referencing a sample template.

    The final code must:
      - Include `import logging` and any needed imports from `typing` or `framework`
      - Use the @activity decorator from `framework.activity_decorator`
      - Inherit from `ActivityBase`
      - Have an `async def execute(self, shared_data) -> ActivityResult:`
      - Possibly reference known manual-coded skills from `skills/skill_*.py` or
        dynamic Composio skills from `framework.api_management.api_manager` (if relevant).
    """

    def __init__(self):
        super().__init__()
        # Updated system prompt with additional guidelines from our experience
        self.system_prompt = (
            "You are an AI coder that converts user suggestions into valid Python activity files.\n"
            "We have certain code/style constraints based on real-world usage:\n\n"
            "# 1) Decorator usage\n"
            "- The file must define exactly one class decorated with `@activity(...)` from `framework.activity_decorator`.\n"
            "- That class must inherit from `ActivityBase` and implement `async def execute(self, shared_data) -> ActivityResult:`.\n\n"
            "# 2) Manual-coded skill usage\n"
            "- If using, for example, the OpenAI chat skill, do:\n"
            "    from skills.skill_chat import chat_skill\n"
            "    if not await chat_skill.initialize():\n"
            '        return ActivityResult.error_result("Chat skill not available")\n'
            '    response = await chat_skill.get_chat_completion(prompt="...")\n'
            "- DO NOT use self.get_skill_instance(...) or skill lookups in shared_data.\n"
            "- DO NOT define new skill constructors inline.\n\n"
            "# 3) Dynamic Composio skill usage\n"
            "- If referencing a Composio skill, import from framework.api_management:\n"
            "    from framework.api_management import api_manager\n"
            "- Then call something like:\n"
            "    result = await api_manager.composio_manager.execute_action(\n"
            "        action=\"TWITTER_TWEET_CREATE\",  # or e.g. 'Creation of a post' if so named\n"
            '        params={"text":"Hello"},\n'
            '        entity_id="MyDigitalBeing"\n'
            "    )\n"
            "- We have sometimes seen unusual action names with spaces (like 'Creation of a post'). That's okay.\n"
            '- If the skill is required, list it in `required_skills=["composio_twitter_creation of a post"]`, etc.\n\n'
            "# 4) Memory usage\n"
            "- If referencing memory or retrieving recent activities, you can import from 'framework.main' or 'framework.memory'.\n"
            "- Typically, do:\n"
            "     from framework.main import DigitalBeing\n"
            "     being = DigitalBeing()\n"
            "     being.initialize()\n"
            "     mem = being.memory.get_recent_activities(limit=10)\n"
            "- We do not store the skill or memory object in `shared_data` as a permanent reference. It's optional if you want.\n\n"
            "# 5) Common pitfalls\n"
            "- DO NOT reference unknown modules or placeholders like 'some_module'.\n"
            "- DO NOT rely on fallback calls to uninitialized XAPISkill, if you do not intend them.\n"
            "- If a dynamic skill name differs from your listing (like 'composio_twitter_twitter_tweet_create'), we might need EXACT naming.\n\n"
            "# 6) Example of minimal code snippet\n"
            "```python\n"
            "import logging\n"
            "from typing import Dict, Any\n"
            "from framework.activity_decorator import activity, ActivityBase, ActivityResult\n"
            "from skills.skill_chat import chat_skill\n"
            "from framework.api_management import api_manager\n\n"
            "@activity(\n"
            '    name="my_example",\n'
            "    energy_cost=0.5,\n"
            "    cooldown=3600,\n"
            '    required_skills=["openai_chat"]  # or dynamic composio skill name\n'
            ")\n"
            "class MyExampleActivity(ActivityBase):\n"
            '    """Short docstring explaining the activity"""\n'
            "    def __init__(self):\n"
            "        super().__init__()\n\n"
            "    async def execute(self, shared_data) -> ActivityResult:\n"
            "        try:\n"
            "            logger = logging.getLogger(__name__)\n"
            '            logger.info("Executing MyExampleActivity")\n\n'
            "            # e.g. using openai_chat:\n"
            "            if not await chat_skill.initialize():\n"
            '                return ActivityResult.error_result("Chat skill not available")\n'
            '            result = await chat_skill.get_chat_completion(prompt="Hello!")\n\n'
            "            # or dynamic composio skill, e.g.:\n"
            "            # result2 = await api_manager.composio_manager.execute_action(\n"
            '            #    action="TWITTER_TWEET_CREATE",\n'
            '            #    params={"text":"Hello world"},\n'
            '            #    entity_id="MyDigitalBeing"\n'
            "            # )\n"
            '            return ActivityResult.success_result({"message":"Done"})\n'
            "        except Exception as e:\n"
            "            return ActivityResult.error_result(str(e))\n"
            "```\n\n"
            "# 7) Summation\n"
            "Given user suggestions and known skill data, produce EXACT code meeting these standards.\n"
            "No triple backticks. Single @activity class only.\n"
        )

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting BuildOrUpdateActivity...")

            # 1) Initialize chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize openai_chat skill"
                )

            # 2) Access the being + memory
            being = DigitalBeing()
            being.initialize()
            recent_activities = being.memory.get_recent_activities(limit=20)

            # 3) Gather skill info (both manual + dynamic)
            skills_config = being.configs.get("skills_config", {})
            manual_skill_list = []
            for skill_name, skill_info in skills_config.items():
                if isinstance(skill_info, dict):
                    desc = f"Skill: {skill_name}, enabled={skill_info.get('enabled')}"
                    req_keys = skill_info.get("required_api_keys", [])
                    desc += f", required_api_keys={req_keys}"
                    meta = skill_info.get("metadata", {})
                    if meta:
                        desc += f", metadata={meta}"
                    manual_skill_list.append(desc)

            dynamic_skills = DynamicComposioSkills.get_all_dynamic_skills()
            dynamic_skill_list = []
            for ds in dynamic_skills:
                d_name = ds["skill_name"]
                d_enabled = ds.get("enabled", True)
                d_req = ds.get("required_api_keys", [])
                d_meta = ds.get("metadata", {})
                desc = f"DynamicSkill: {d_name}, enabled={d_enabled}, required_api_keys={d_req}, metadata={d_meta}"
                dynamic_skill_list.append(desc)

            all_skills_block = "\n".join(manual_skill_list + dynamic_skill_list)
            if not all_skills_block.strip():
                all_skills_block = "(No known skills found)"

            # 4) Find last suggestions from memory (SuggestNewActivities)
            suggestion_texts = []
            for act in recent_activities:
                if act["activity_type"] == "SuggestNewActivities":
                    data_content = act.get("data", {})
                    if isinstance(data_content, dict) and "suggestions" in data_content:
                        suggestion_texts.append(data_content["suggestions"])

            if not suggestion_texts:
                return ActivityResult(
                    success=False,
                    error="No recent suggestions in memory; cannot build new activity",
                )
            combined_suggestions = "\n---\n".join(suggestion_texts)

            # ---------------------------------------------------------------------
            # A) FIRST LLM CALL - GET A SHORT FILENAME
            # ---------------------------------------------------------------------
            filename_prompt = (
                f"User Suggestions:\n{combined_suggestions}\n\n"
                f"Known Skills:\n{all_skills_block}\n\n"
                "Propose a short new file name that starts with 'activity_' and ends with '.py'. "
                "Do NOT provide any code, just the file name (no quotes, no backticks)."
            )

            filename_resp = await chat_skill.get_chat_completion(
                prompt=filename_prompt, system_prompt=self.system_prompt, max_tokens=50
            )
            if not filename_resp["success"]:
                return ActivityResult(success=False, error=filename_resp["error"])

            raw_filename = filename_resp["data"]["content"].strip()
            match_name = re.search(r"(activity_[\w-]+\.py)", raw_filename)
            if match_name:
                filename = match_name.group(1)
            else:
                filename = "activity_new_suggestion.py"

            # ---------------------------------------------------------------------
            # B) SECOND LLM CALL - GET THE FULL CODE
            # ---------------------------------------------------------------------
            code_prompt = (
                f"User Suggestions:\n{combined_suggestions}\n\n"
                f"Known Skills:\n{all_skills_block}\n\n"
                "Below is an example minimal template that shows how we want to reference manual-coded skills "
                "or dynamic composio skills:\n"
                "```python\n"
                "import logging\n"
                "from typing import Dict, Any\n"
                "from framework.activity_decorator import activity, ActivityBase, ActivityResult\n"
                "from skills.skill_chat import chat_skill\n"
                "from framework.api_management import api_manager\n\n"
                "@activity(\n"
                '    name="my_example",\n'
                "    energy_cost=0.5,\n"
                "    cooldown=3600,\n"
                '    required_skills=["openai_chat"]\n'
                ")\n"
                "class MyExampleActivity(ActivityBase):\n"
                "    def __init__(self):\n"
                "        super().__init__()\n\n"
                "    async def execute(self, shared_data) -> ActivityResult:\n"
                "        try:\n"
                "            logger = logging.getLogger(__name__)\n"
                '            logger.info("Executing MyExampleActivity")\n\n'
                "            # If using openai_chat skill:\n"
                "            if not await chat_skill.initialize():\n"
                '                return ActivityResult.error_result("Chat skill not available")\n'
                '            result = await chat_skill.get_chat_completion(prompt="Hello!")\n\n'
                "            # If using dynamic composio skill, e.g. 'composio_twitter_twitter_tweet_create':\n"
                "            #    result2 = await api_manager.composio_manager.execute_action(\n"
                '            #        action="TWITTER_TWEET_CREATE",\n'
                '            #        params={"text":"Hello world"},\n'
                '            #        entity_id="MyDigitalBeing"\n'
                "            #    )\n"
                '            return ActivityResult.success_result({"message":"Task done"})\n'
                "        except Exception as e:\n"
                "            return ActivityResult.error_result(str(e))\n"
                "```\n\n"
                f"Now produce a FULL Python file named {filename} with exactly one activity class that meets the instructions:\n"
                "- Single @activity decorator\n"
                "- Inherit from ActivityBase\n"
                "- Has `async def execute(...)`\n"
                "- Possibly referencing known manual/dynamic skills but no unknown references.\n"
                "- DO NOT wrap your code in triple backticks.\n"
            )

            code_resp = await chat_skill.get_chat_completion(
                prompt=code_prompt, system_prompt=self.system_prompt, max_tokens=1200
            )
            if not code_resp["success"]:
                return ActivityResult(success=False, error=code_resp["error"])

            code_snippet = code_resp["data"]["content"]
            code_snippet = self._clean_code_snippet(code_snippet)

            # ---------------------------------------------------------------------
            # Write to disk + Reload
            # ---------------------------------------------------------------------
            success = write_activity_code(filename, code_snippet)
            if not success:
                return ActivityResult(
                    success=False, error=f"Failed to write {filename} to disk"
                )

            # Reload so the new activity is recognized immediately
            being.activity_loader.reload_activities()

            return ActivityResult(
                success=True,
                data={"filename": filename, "code_snippet": code_snippet},
                metadata={"message": "Activity created/updated and reloaded"},
            )

        except Exception as e:
            logger.error(f"Error in BuildOrUpdateActivity: {e}", exc_info=True)
            return ActivityResult(success=False, error=str(e))

    def _clean_code_snippet(self, snippet: str) -> str:
        """
        Remove triple-backtick fences (` ```python ` or ` ``` `) from the snippet,
        plus any leading/trailing whitespace.
        """
        snippet = snippet.strip()
        # Remove any leading ```python or ```
        snippet = re.sub(r"^```(?:python)?", "", snippet, flags=re.IGNORECASE).strip()
        # Remove any trailing ```
        snippet = re.sub(r"```$", "", snippet).strip()
        return snippet


##### my_digital_being/activities/activity_daily_thought.py #####
"""Activity for generating exploratory daily thoughts using emergent research insights."""

import logging
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="daily_thought",
    energy_cost=0.4,
    cooldown=1800,  # 30 minutes
    required_skills=["openai_chat"],
)
class DailyThoughtActivity(ActivityBase):
    """Generates exploratory daily thoughts inspired by emergent research insights."""

    def __init__(self):
        super().__init__()
        self.system_prompt = (
            "You are a curious and insightful AI that generates thought-provoking daily reflections "
            "inspired by cutting-edge research and emergent patterns. Your goal is to:\n"
            "1. Push the boundaries of conventional thinking\n"
            "2. Explore novel connections and possibilities\n"
            "3. Question assumptions and paradigms\n"
            "4. Inspire new ways of seeing familiar concepts\n\n"
            "Keep responses concise (2-3 sentences) but make them intellectually stimulating and focused on "
            "unexplored territories and emerging patterns in science and technology."
        )

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the daily thought activity."""
        try:
            logger.info("Starting exploratory thought generation")

            # Get memory reference using the standard pattern
            system_data = shared_data.get_category_data("system")
            memory = system_data.get("memory_ref")
            
            if not memory:
                # Fallback to a global digital being's memory reference
                from framework.main import DigitalBeing
                being = DigitalBeing()
                being.initialize()
                memory = being.memory

            # Look for recent emergent research insights in activity history
            recent_activities = memory.get_recent_activities(limit=10)
            emergent_insights = None
            
            for activity in recent_activities:
                if activity["activity_type"] == "EmergentResearchActivity" and activity["success"]:
                    if "data" in activity and "insights" in activity["data"]:
                        emergent_insights = activity["data"]["insights"]
                        break

            # Initialize required chat skill
            if not await chat_skill.initialize():
                return ActivityResult.error_result("Failed to initialize chat skill")

            # Prepare the prompt based on available insights
            if emergent_insights:
                prompt = (
                    "Drawing inspiration from recent research insights:\n"
                    f"{emergent_insights}\n\n"
                    "Generate a thought-provoking reflection that explores the unknowns and "
                    "possibilities suggested by these patterns. Focus on novel angles and unexplored implications."
                )
            else:
                prompt = (
                    "Generate a thought-provoking reflection that challenges conventional thinking and "
                    "explores the frontiers of what's possible. Focus on emerging patterns and unexplored "
                    "territories in science and technology."
                )

            # Generate the thought using the chat skill
            result = await chat_skill.get_chat_completion(
                prompt=prompt, system_prompt=self.system_prompt, max_tokens=100
            )
            if not result["success"]:
                return ActivityResult.error_result(result["error"])
            
            return ActivityResult.success_result(
                data={
                    "thought": result["data"]["content"],
                    "has_research_context": bool(emergent_insights),
                },
                metadata={
                    "model": result["data"]["model"],
                    "finish_reason": result["data"]["finish_reason"],
                    "inspired_by": "emergent_insights" if emergent_insights else "exploration",
                },
            )

        except Exception as e:
            logger.error(f"Error in daily thought activity: {e}")
            return ActivityResult.error_result(str(e))


##### my_digital_being/activities/activity_draw.py #####
"""Drawing activity implementation."""

import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_generate_image import ImageGenerationSkill
from framework.api_management import api_manager

logger = logging.getLogger(__name__)


@activity(
    name="draw",
    energy_cost=0.6,
    cooldown=3600, 
    required_skills=["image_generation"],
)
class DrawActivity(ActivityBase):
    def __init__(self):
        super().__init__()
        self.default_size = (1024, 1024)
        self.default_format = "png"

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the drawing activity."""
        try:
            logger.info("Starting drawing activity")

            # Initialize the image generation skill with configuration
            image_skill = ImageGenerationSkill(
                {
                    "enabled": True,
                    "max_generations_per_day": 50,
                    "supported_formats": ["png", "jpg"],
                }
            )

            # Verify the skill can generate images
            if not await image_skill.can_generate():
                error_msg = "Image generation is not available at this time"
                logger.error(error_msg)
                return ActivityResult(success=False, error=error_msg)

            # Generate drawing prompt
            prompt = self._generate_prompt(shared_data)

            # Generate the image
            result = await image_skill.generate_image(
                prompt=prompt, size=self.default_size, format=self.default_format
            )

            if result.get("success"):
                # Store the generated image data
                shared_data.set(
                    "memory",
                    f"drawing_{result['image_data']['generation_id']}",
                    {"prompt": prompt, "image_data": result["image_data"]},
                )

                logger.info(f"Successfully generated image for prompt: {prompt}")
                return ActivityResult(
                    success=True,
                    data={
                        "generation_id": result["image_data"]["generation_id"],
                        "prompt": prompt,
                        "image_data": result["image_data"],
                    },
                    metadata={"size": self.default_size, "format": self.default_format},
                )
            else:
                error_msg = result.get("error", "Unknown error")
                logger.error(f"Failed to generate image: {error_msg}")
                return ActivityResult(success=False, error=error_msg)

        except Exception as e:
            logger.error(f"Failed to generate drawing: {e}")
            return ActivityResult(success=False, error=str(e))

    def _generate_prompt(self, shared_data) -> str:
        """Generate a drawing prompt based on current state and memory."""
        state = shared_data.get("state", "current_state", {})
        personality = state.get("personality", {})
        mood = state.get("mood", "neutral")

        # Base prompts for different moods
        mood_prompts = {
            "happy": "a sunny landscape with vibrant colors",
            "neutral": "a peaceful scene with balanced composition",
            "sad": "a rainy day with muted colors",
        }

        # Get base prompt from mood
        base_prompt = mood_prompts.get(mood, mood_prompts["neutral"])

        # Modify based on personality
        if personality.get("creativity", 0) > 0.7:
            base_prompt += " with surreal elements"
        if personality.get("curiosity", 0) > 0.7:
            base_prompt += " featuring unexpected details"

        return f"Digital artwork of {base_prompt}, digital art style"


##### my_digital_being/activities/activity_emergent_research.py #####
"""Activity for generating emergent insights by combining research from multiple sources."""

import logging
from typing import Dict, Any, List
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="emergent_research",
    energy_cost=0.5,
    cooldown=7200,  # 2 hours
    required_skills=["openai_chat"],
)
class EmergentResearchActivity(ActivityBase):
    """Analyzes research data to generate emergent insights through combinatory play."""

    def __init__(self):
        super().__init__()
        self.system_prompt = """You are an innovative AI researcher skilled at identifying 
        patterns, connections, and novel insights across different research papers and web content. 
        Your goal is to practice combinatory play - connecting seemingly unrelated ideas to generate 
        new insights and hypotheses. Focus on:
        1. Identifying common themes and patterns
        2. Finding unexpected connections between different topics
        3. Generating novel hypotheses and research directions
        4. Highlighting potential breakthroughs or innovative applications
        
        Be specific and concrete in your analysis while maintaining scientific rigor."""

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the emergent research analysis activity."""
        try:
            logger.info("Starting emergent research analysis")

            # Get memory reference using the standard pattern
            system_data = shared_data.get_category_data("system")
            memory = system_data.get("memory_ref")

            if not memory:
                # Fallback to a global digital being's memory reference
                from framework.main import DigitalBeing
                being = DigitalBeing()
                being.initialize()
                memory = being.memory

            # Look for research data in recent activities
            recent_activities = memory.get_recent_activities(limit=20)
            arxiv_papers = []
            web_research = []

            for activity in recent_activities:
                if activity["success"]:
                    if activity["activity_type"] == "FetchResearchActivity" and "data" in activity:
                        if "papers" in activity["data"]:
                            arxiv_papers.extend(activity["data"]["papers"])
                    elif activity["activity_type"] == "WebResearchActivity" and "data" in activity:
                        if "synthesis" in activity["data"]:
                            web_research.append(activity["data"])

            if not arxiv_papers and not web_research:
                return ActivityResult.error_result("No research data found in recent activities")

            # Initialize chat skill
            if not await chat_skill.initialize():
                return ActivityResult.error_result("Failed to initialize chat skill")

            # Prepare research summary for analysis
            research_summary = self._prepare_research_summary(arxiv_papers, web_research)

            # Generate emergent insights
            analysis_prompt = f"""Analyze the following research data and generate emergent insights:

            Research Data:
            {research_summary}

            Please provide:
            1. Key patterns and themes identified across sources
            2. Novel connections between different topics
            3. Potential breakthrough ideas or hypotheses
            4. Suggested directions for future research
            """

            result = await chat_skill.get_chat_completion(
                prompt=analysis_prompt,
                system_prompt=self.system_prompt,
                max_tokens=1000,
            )

            if not result["success"]:
                return ActivityResult.error_result(result["error"])

            return ActivityResult.success_result(
                data={
                    "insights": result["data"]["content"],
                    "source_counts": {
                        "arxiv_papers": len(arxiv_papers),
                        "web_sources": len(web_research)
                    }
                },
                metadata={
                    "model": result["data"]["model"],
                    "finish_reason": result["data"]["finish_reason"],
                }
            )

        except Exception as e:
            logger.error(f"Error in emergent research activity: {e}")
            return ActivityResult.error_result(str(e))

    def _prepare_research_summary(self, arxiv_papers: List[Dict], web_research: List[Dict]) -> str:
        """Prepare a formatted summary of research data for analysis."""
        summary_parts = []

        if arxiv_papers:
            summary_parts.append("ArXiv Papers:")
            for paper in arxiv_papers:
                summary_parts.append(f"- Title: {paper.get('title')}")
                summary_parts.append(f"  Abstract: {paper.get('summary')}")
                summary_parts.append(f"  Categories: {paper.get('categories', [])}\n")

        if web_research:
            summary_parts.append("Web Research:")
            for item in web_research:
                summary_parts.append(f"- Title: {item.get('title')}")
                summary_parts.append(f"  Content: {item.get('content')}")
                summary_parts.append(f"  URL: {item.get('url')}\n")

        return "\n".join(summary_parts) 

##### my_digital_being/activities/activity_evaluate.py #####
# activities/activity_evaluate.py

import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="EvaluateActivity",
    energy_cost=0.3,
    cooldown=86400,  # example: 1 day
    required_skills=["openai_chat"],
)
class EvaluateActivity(ActivityBase):
    """
    Activity that attempts to 'simulate' how effective a newly generated activity might be
    or identify potential problems. This is purely an LLM-based guess, not guaranteed accurate.
    """

    def __init__(self):
        super().__init__()
        self.system_prompt = """You are an AI that evaluates the potential effectiveness
        of newly generated Activities. You consider whether the code is likely to run,
        fits the being's objectives, and avoids major pitfalls.
        Provide a short bullet-point analysis.
        """

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting EvaluateActivity...")

            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize openai_chat skill"
                )

            # Possibly fetch the last created/updated code from memory
            from framework.main import DigitalBeing

            being = DigitalBeing()
            being.initialize()
            recents = being.memory.get_recent_activities(limit=10)
            code_found = None

            for act in recents:
                if act["activity_type"] == "BuildOrUpdateActivity" and act.get(
                    "data", {}
                ):
                    data_content = act["data"]
                    if "code_snippet" in data_content:
                        code_found = data_content["code_snippet"]
                        break

            if not code_found:
                return ActivityResult(
                    success=False, error="No newly generated code found to evaluate"
                )

            prompt_text = (
                f"Here is the code for a newly created activity:\n{code_found}\n\n"
                "Evaluate how effective or risky this might be. Provide bullet points. "
                "Focus on alignment with objectives, potential errors, or improvements."
            )

            response = await chat_skill.get_chat_completion(
                prompt=prompt_text, system_prompt=self.system_prompt, max_tokens=250
            )
            if not response["success"]:
                return ActivityResult(success=False, error=response["error"])

            evaluation = response["data"]["content"]
            return ActivityResult(
                success=True,
                data={"evaluation": evaluation},
                metadata={
                    "model": response["data"]["model"],
                    "finish_reason": response["data"]["finish_reason"],
                },
            )

        except Exception as e:
            logger.error(f"Error in EvaluateActivity: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_fetch_research.py #####
"""Activity for fetching research papers from arXiv."""

import logging
from typing import Dict, Any, List
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_arxiv import ArxivSkill

logger = logging.getLogger(__name__)


@activity(
    name="fetch_research",
    energy_cost=0.3,
    cooldown=3600,  # 1 hour
    required_skills=["arxiv_search"],
)
class FetchResearchActivity(ActivityBase):
    def __init__(self):
        super().__init__()
        self.categories = ["cs.AI", "cs.CL", "cs.LG"]  # AI, Comp Ling, Machine Learning
        self.max_papers = 5
        self.default_query = "artificial intelligence OR machine learning OR neural networks"

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the research paper fetching activity."""
        try:
            logger.info("Starting research paper fetch activity")

            # Initialize the ArXiv skill with configuration
            arxiv_skill = ArxivSkill()

            # Get memory reference
            system_data = shared_data.get_category_data("system")
            memory = system_data.get("memory_ref")
            
            # Fetch papers for each category
            all_papers = []
            for category in self.categories:
                papers = await arxiv_skill.search_papers(
                    query=self.default_query,
                    max_results=self.max_papers,
                    category=category
                )
                all_papers.extend(papers)

            # Store papers in memory
            if memory:
                memory.store_data("latest_research", all_papers)

            logger.info(f"Successfully fetched {len(all_papers)} papers")
            return ActivityResult(
                success=True,
                data={"papers": all_papers, "count": len(all_papers)},
                metadata={
                    "categories": self.categories,
                    "max_papers_per_category": self.max_papers,
                    "query": self.default_query
                },
            )

        except Exception as e:
            logger.error(f"Failed to fetch research papers: {e}")
            return ActivityResult(success=False, error=str(e)) 

##### my_digital_being/activities/activity_nap.py #####
"""
Activity for taking a "nap" to simulate resting. 
We store a 'napping' state in shared_data, then return success.
"""

import logging
from typing import Dict, Any, List
from framework.activity_decorator import activity, ActivityBase, ActivityResult

logger = logging.getLogger(__name__)


@activity(
    name="nap",
    energy_cost=0,  # A nap might not cost energy, or you can set 0.2, etc.
    cooldown=1800,  # e.g. a 30-minute cooldown between naps
)
class NapActivity(ActivityBase):
    def __init__(self):
        super().__init__()
        self.nap_minutes = 15  # length of nap in minutes

    async def execute(self, shared_data) -> ActivityResult:
        """
        Execute the nap activity.
        We'll simulate a 'nap' by logging that we're napping,
        then store a record in shared_data that a nap took place.
        """
        try:
            logger.info(f"Taking a {self.nap_minutes}-minute nap.")
            # You can imagine "await asyncio.sleep(...)" if you wanted a real delay.

            # Store a record in shared_data:
            # e.g., shared_data.set('body_state', 'currently_napping', True)
            # or log the timestamp, etc.
            shared_data.set(
                "body_state",
                "nap_info",
                {"last_nap_duration": self.nap_minutes, "timestamp": "Just now!"},
            )

            logger.info("Nap finished. Feeling refreshed!")
            return ActivityResult(
                success=True,
                data={"nap_minutes": self.nap_minutes},
                metadata={
                    "message": "Nap complete",
                },
            )

        except Exception as e:
            logger.error(f"Nap failed: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_suggest_new_activities.py #####
# activities/activity_suggest_new_activities.py

import logging
from typing import Any, Dict
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill

# We import these so we can list out both manual + dynamic skill records
from framework.skill_config import DynamicComposioSkills
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)


@activity(
    name="SuggestNewActivities",
    energy_cost=0.4,
    cooldown=259200,  # 3 days
    required_skills=["openai_chat"],
)
class SuggestNewActivities(ActivityBase):
    """
    Activity that examines the being's current objectives and constraints,
    then asks the LLM to propose new or modified Activities which may leverage
    any known skills (both manual-coded + dynamic from Composio).
    """

    def __init__(self):
        super().__init__()
        self.system_prompt = """You are an AI that helps brainstorm new or improved
Activities (Python-coded tasks) to achieve the being's goals, leveraging the skills
the system has available. The user will evaluate or build these later. Provide short,
actionable suggestions focusing on feasibility, alignment with constraints, and creativity.
If relevant, mention which skill(s) would be used for each suggestion.
        Do not plan on using API calls or making up URLs and rely on available skills for interacting with anything external to yourself."""

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting new activity suggestion process...")

            # 1) Initialize the chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize openai_chat skill"
                )

            # 2) Gather the being + config
            being = DigitalBeing()
            being.initialize()
            char_cfg = being.configs.get("character_config", {})
            objectives = char_cfg.get("objectives", {})
            primary_obj = objectives.get("primary", "No primary objective found.")
            constraints_cfg = being.configs.get("activity_constraints", {})
            global_cons = constraints_cfg.get("global_constraints", "None specified")

            # 3) Gather all known skills (manual + dynamic)
            skills_config = being.configs.get("skills_config", {})

            # A. Manual-coded skills from skills_config.json
            manual_skill_list = []
            for skill_name, skill_info in skills_config.items():
                # skill_info can be dict or something else
                if isinstance(skill_info, dict):
                    # We'll build a short desc
                    desc = f"Skill: {skill_name}, enabled={skill_info.get('enabled')}"
                    # Add required keys, etc. if relevant
                    req_keys = skill_info.get("required_api_keys", [])
                    desc += f", required_api_keys={req_keys}"
                    meta = skill_info.get("metadata", {})
                    if meta:
                        desc += f", metadata={meta}"
                    manual_skill_list.append(desc)
                else:
                    # e.g. skip "default_llm_skill": "openai_chat"
                    pass

            # B. Dynamic (Composio) discovered skills
            dynamic_skills = DynamicComposioSkills.get_all_dynamic_skills()
            dynamic_skill_list = []
            for ds in dynamic_skills:
                d_name = ds["skill_name"]
                d_enabled = ds.get("enabled", True)
                d_req = ds.get("required_api_keys", [])
                d_meta = ds.get("metadata", {})
                desc = f"DynamicSkill: {d_name}, enabled={d_enabled}, required_api_keys={d_req}, metadata={d_meta}"
                dynamic_skill_list.append(desc)

            # 4) Combine skill descriptions into one block
            all_skills_block = "\n".join(manual_skill_list + dynamic_skill_list)
            if not all_skills_block.strip():
                all_skills_block = "(No known skills found)"

            # 5) Build final prompt
            prompt_text = (
                f"My primary objective: {primary_obj}\n"
                f"Global constraints or notes: {global_cons}\n\n"
                f"Known Skills:\n{all_skills_block}\n\n"
                f"Propose up to 3 new or modified Activities to help achieve my goal. "
                f"Highlight how each might use one or more of these skills (if relevant). "
                f"Keep suggestions short."
            )

            # 6) LLM call
            response = await chat_skill.get_chat_completion(
                prompt=prompt_text, system_prompt=self.system_prompt, max_tokens=300
            )
            if not response["success"]:
                return ActivityResult(success=False, error=response["error"])

            suggestions = response["data"]["content"]

            return ActivityResult(
                success=True,
                data={"suggestions": suggestions},
                metadata={
                    "model": response["data"]["model"],
                    "finish_reason": response["data"]["finish_reason"],
                },
            )

        except Exception as e:
            logger.error(f"Error in SuggestNewActivities: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_test.py #####
import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult

logger = logging.getLogger(__name__)


@activity(name="Test", energy_cost=0.2, cooldown=300, required_skills=[])
class TestActivity(ActivityBase):
    def __init__(self):
        super().__init__()

    async def execute(self, shared_data) -> ActivityResult:
        try:
            # Example: This is the main logic for "Test" activity
            logger.info("Executing Test activity")
            # TODO: Actual logic goes here
            return ActivityResult(success=True, data={"message": "Test done"})
        except Exception as e:
            logger.error(f"Error in Test activity: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_web_research.py #####
"""
Web Research Activity

This activity allows the AI to perform web research on topics it's interested in
or needs to learn about. It uses the web search skill to gather information.
"""

import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_web_search import web_search_skill

logger = logging.getLogger(__name__)


@activity(
    name="web_research",
    energy_cost=0.3,
    cooldown=3600,  # 1 hour
    required_skills=["web_search"],
)
class WebResearchActivity(ActivityBase):
    """Activity for conducting web research on topics of interest."""

    def __init__(self):
        super().__init__()
        self.default_topic = "latest developments in artificial intelligence"

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the web research activity."""
        try:
            logger.info("Starting web research activity")

            # Initialize the Web Search skill
            if not await web_search_skill.initialize():
                return ActivityResult(
                    success=False,
                    error="Failed to initialize web search skill"
                )

            # Get memory reference
            system_data = shared_data.get_category_data("system")
            memory = system_data.get("memory_ref")

            # Get the research topic or use default
            topic = shared_data.get("research_topic", self.default_topic)
            logger.info(f"Starting web research on topic: {topic}")

            # Perform the web search
            response = await web_search_skill.search(
                query=topic,
                search_depth="advanced",
                topic="general",
                time_range="month",
                max_tokens=4000
            )

            if not response["success"]:
                return ActivityResult(
                    success=False,
                    error="Failed to gather research data"
                )

            # Store results in memory
            research_data = {
                "type": "research",
                "topic": topic,
                "findings": response["data"]["context"],
                "timestamp": shared_data.get("timestamp", "")
            }

            if memory:
                memory.store_data("web_research", research_data)

            logger.info(f"Successfully completed web research on: {topic}")
            return ActivityResult(
                success=True,
                data=research_data,
                metadata={
                    "topic": topic,
                    "search_config": response["data"]["used_config"]
                }
            )

        except Exception as e:
            logger.error(f"Failed to perform web research: {e}")
            return ActivityResult(success=False, error=str(e))


# Global instance
activity = WebResearchActivity() 

##### my_digital_being/server.py #####
"""
Digital Being Server implementation.
Implements:
 - /oauth_callback endpoint to finalize OAuth after user is redirected back
 - WebSocket commands for front-end
 - Pause/Resume logic
 - Checking is_configured for front-end
 - [ADDED] Returning 'enabled' status for each loaded activity
"""

import asyncio
import json
import logging
import http
import mimetypes
from pathlib import Path
from typing import Dict, Any, Set, Union, Tuple
from datetime import datetime

import websockets
from websockets.server import serve
from websockets.legacy.server import WebSocketServerProtocol

# Initialize the logger with logging.INFO before importing other modules
# to make sure INFO level logs are printed (Otherwise it gets set to WARN)
logging.basicConfig(level=logging.INFO)

# Import api_manager at top-level (not again inside any function)
from framework.api_management import api_manager
from framework.main import DigitalBeing
from framework.skill_config import DynamicComposioSkills

logger = logging.getLogger(__name__)


class DigitalBeingServer:
    """Server for the Digital Being application."""

    def __init__(self, host: str = "0.0.0.0", port: int = 8000):
        self.host = host
        self.port = port
        self.clients: Set[WebSocketServerProtocol] = set()
        self.being = DigitalBeing()
        self.being_state: Dict[str, Any] = {}
        self.static_path = Path(__file__).parent / "static"

        # Additional flags for running/paused
        self.running = False
        self.paused = False

    async def initialize(self):
        """Initialize the digital being and start periodic updates."""
        logger.info("Initializing Digital Being...")
        self.being.initialize()  # load config, etc.

        self.running = True  # default "running"
        asyncio.create_task(self._periodic_state_update())
        asyncio.create_task(self._run_being_loop())

    async def _run_being_loop(self):
        """Main loop that calls the being's activities if running & not paused."""
        while True:
            try:
                if not self.running:
                    await asyncio.sleep(2)
                    continue

                if self.paused:
                    await asyncio.sleep(2)
                    continue

                if not self.being.is_configured():
                    # If not configured, do nothing in the main loop
                    await asyncio.sleep(2)
                    continue

                # Single-step approach for selecting an activity
                current_activity = self.being.activity_selector.select_next_activity()
                if current_activity:
                    logger.info(
                        f"Executing activity: {current_activity.__class__.__name__}"
                    )
                    result = await self.being.execute_activity(current_activity)
                    if result and result.success:
                        self.being_state["last_activity"] = {
                            "name": current_activity.__class__.__name__,
                            "timestamp": datetime.now().isoformat(),
                            "success": True,
                        }
                    else:
                        self.being_state["last_activity"] = {
                            "name": current_activity.__class__.__name__,
                            "timestamp": datetime.now().isoformat(),
                            "success": False,
                            "error": (result.error if result else "Unknown error"),
                        }
                    await self.broadcast_state()

                self.being.state.update()
                self.being.memory.persist()
                await asyncio.sleep(5)

            except Exception as e:
                logger.error(f"Error in being loop: {e}")
                await asyncio.sleep(10)

    async def _periodic_state_update(self):
        """Periodically update and broadcast the being's state every second."""
        while True:
            try:
                current_state = self.being.state.get_current_state()
                # Provide 'configured' and 'paused' status
                current_state["configured"] = self.being.is_configured()
                current_state["paused"] = self.paused

                if current_state != self.being_state:
                    self.being_state = current_state
                    await self.broadcast_state()
                await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"Error in periodic state update: {e}")
                await asyncio.sleep(5)

    async def register(self, websocket: WebSocketServerProtocol):
        self.clients.add(websocket)
        logger.info(f"Client connected. Total clients: {len(self.clients)}")

        # Send the current state right away
        await websocket.send(
            json.dumps({"type": "state_update", "data": self.being_state})
        )

    async def unregister(self, websocket: WebSocketServerProtocol):
        self.clients.discard(websocket)
        logger.info(f"Client disconnected. Total clients: {len(self.clients)}")

    async def serve_static_file(
        self, path: str, request_headers: Dict
    ) -> Union[Tuple[http.HTTPStatus, list, bytes], None]:
        try:
            if path == "/ws":
                return None

            if path.startswith("/oauth_callback"):
                return await self.handle_oauth_http_callback(path)

            if not isinstance(path, str):
                return None

            request_path = "/" + path.lstrip("/")
            if request_path == "/":
                request_path = "/index.html"

            if request_path == "/ws":
                if (
                    request_headers.get("Upgrade", "").lower() == "websocket"
                    and request_headers.get("Connection", "").lower() == "upgrade"
                ):
                    logger.info("Valid WebSocket upgrade request")
                    return None
                logger.warning("Invalid WebSocket request")
                return (
                    http.HTTPStatus.BAD_REQUEST,
                    [("Content-Type", "text/plain")],
                    b"Invalid WebSocket request",
                )

            file_path = self.static_path / request_path.lstrip("/")
            if not file_path.exists() or not file_path.is_file():
                logger.warning(f"File not found: {file_path}")
                return (
                    http.HTTPStatus.NOT_FOUND,
                    [("Content-Type", "text/plain")],
                    b"404 Not Found",
                )

            content_type, _ = mimetypes.guess_type(str(file_path))
            if not content_type:
                content_type = "application/octet-stream"

            content = file_path.read_bytes()
            return (
                http.HTTPStatus.OK,
                [
                    ("Content-Type", content_type),
                    ("Cache-Control", "public, max-age=3600"),
                ],
                content,
            )

        except Exception as e:
            logger.error(f"Error serving {path}: {e}")
            return (
                http.HTTPStatus.INTERNAL_SERVER_ERROR,
                [("Content-Type", "text/plain")],
                b"Internal Server Error",
            )

    async def handle_oauth_http_callback(self, path: str):
        """
        Handle GET /oauth_callback?status=success&connectedAccountId=...&appName=...
        Then finalize or store connection info, auto-fetch & register app actions,
        and finally redirect to "/".
        """
        from urllib.parse import urlparse, parse_qs

        parsed = urlparse(path)
        query = parse_qs(parsed.query)

        status = query.get("status", [""])[0]
        connected_account_id = query.get("connectedAccountId", [None])[0]
        app_name = query.get("appName", [""])[0]
        code = query.get("code", [None])[0]

        if not connected_account_id:
            logger.error("Missing connectedAccountId param in /oauth_callback")
            body = b"Missing connectedAccountId param"
            return (
                http.HTTPStatus.BAD_REQUEST,
                [("Content-Type", "text/plain")],
                body,
            )

        logger.info(
            f"OAuth callback success for app={app_name}, connectedAccountId={connected_account_id}, status={status}"
        )

        try:
            if code:
                finalize_result = (
                    await api_manager.composio_manager.handle_oauth_callback(
                        connected_account_id, code
                    )
                )
                logger.info(f"handle_oauth_callback returned: {finalize_result}")
            else:
                if app_name:
                    api_manager.composio_manager.mark_app_connected_without_code(
                        app_name, connected_account_id
                    )

            if app_name:
                logger.info(
                    f"Auto-fetching actions for newly connected app: {app_name}"
                )
                actions_result = await api_manager.list_actions_for_app(app_name)
                if actions_result.get("success"):
                    actions = actions_result.get("actions", [])
                    if actions:
                        logger.info(
                            f"Discovered {len(actions)} actions for {app_name}, registering now..."
                        )
                        DynamicComposioSkills.register_composio_actions(
                            app_name, actions
                        )
                    else:
                        logger.warning(f"No actions found for {app_name}.")
                else:
                    logger.warning(
                        f"Failed to fetch actions for {app_name}: {actions_result.get('error')}"
                    )

        except Exception as e:
            logger.error(
                f"Error finalizing/fetching actions for {app_name}: {e}", exc_info=True
            )

        redirect_body = b'<html><head><meta http-equiv="refresh" content="0;URL=\'/\'" /></head><body>Redirecting...</body></html>'
        return (
            http.HTTPStatus.OK,
            [("Content-Type", "text/html")],
            redirect_body,
        )

    async def handle_websocket(self, websocket: WebSocketServerProtocol, path: str):
        """Handle WebSocket connections at /ws."""
        try:
            if path != "/ws":
                logger.warning(f"Invalid WebSocket path: {path}")
                await websocket.close(code=1008, reason="Invalid path")
                return

            await self.register(websocket)
            try:
                async for message in websocket:
                    try:
                        data = json.loads(message)
                        await self.process_message(websocket, data)
                    except json.JSONDecodeError:
                        logger.error(f"Invalid JSON: {message}")
                    except Exception as e:
                        logger.error(f"Error processing WS message: {e}")
            except websockets.ConnectionClosed:
                logger.info("WebSocket closed normally")
            except Exception as e:
                logger.error(f"WebSocket error: {e}")
        finally:
            await self.unregister(websocket)

    async def process_message(
        self, websocket: WebSocketServerProtocol, data: Dict[str, Any]
    ):
        try:
            message_type = data.get("type")
            if not message_type:
                logger.warning("No message type in WS data!")
                return

            if message_type == "get_state":
                await websocket.send(
                    json.dumps({"type": "state_update", "data": self.being_state})
                )
            elif message_type == "command":
                command = data.get("command")
                if command:
                    resp = await self.handle_command(command, data.get("params", {}))
                    await websocket.send(
                        json.dumps(
                            {
                                "type": "command_response",
                                "command": command,
                                "response": resp,
                            }
                        )
                    )
        except Exception as e:
            logger.error(f"Error in process_message: {e}")
            await websocket.send(json.dumps({"type": "error", "message": str(e)}))

    async def handle_command(
        self, command: str, params: Dict[str, Any]
    ) -> Dict[str, Any]:
        logger.debug(f"handle_command: {command}, params={params}")
        try:
            if command == "pause":
                self.paused = True
                return {"success": True, "message": "Digital Being is paused."}
            elif command == "resume":
                self.paused = False
                return {"success": True, "message": "Digital Being resumed."}
            elif command == "stop_loop":
                self.running = False
                return {"success": True, "message": "Core loop stopped."}
            elif command == "start_loop":
                self.running = True
                return {"success": True, "message": "Core loop started."}

            elif command == "initiate_oauth":
                app_name = params.get("app_name")
                base_url = params.get("base_url", "http://localhost:8000")
                if not app_name:
                    return {"success": False, "error": "Missing app_name"}
                redirect_url = f"{base_url}/oauth_callback"
                try:
                    result = await api_manager.composio_manager.initiate_oauth_flow(
                        app_name, redirect_url
                    )
                    return result
                except Exception as e:
                    logger.error(f"init_oauth error: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "get_composio_integrations":
                try:
                    integrations = (
                        await api_manager.composio_manager.list_available_integrations()
                    )
                    return {"success": True, "composio_integrations": integrations}
                except Exception as e:
                    logger.error(f"Error get_composio_integrations: {e}")
                    return {
                        "success": False,
                        "error": str(e),
                        "composio_integrations": [],
                    }

            elif command == "get_api_key_status":
                skills_status = await api_manager.get_skill_status()
                return {"success": True, "skills": skills_status}

            elif command == "configure_api_key":
                skill_name = params.get("skill_name")
                key_name = params.get("key_name")
                api_key_value = params.get("api_key")
                if not all([skill_name, key_name, api_key_value]):
                    return {"success": False, "message": "Missing required params"}
                try:
                    result = await api_manager.set_api_key(
                        skill_name, key_name, api_key_value
                    )
                    return result
                except Exception as e:
                    return {"success": False, "message": str(e)}

            elif command == "get_system_status":
                memory_stats = {
                    "short_term_count": len(self.being.memory.short_term_memory),
                    "long_term_count": sum(
                        len(x) for x in self.being.memory.long_term_memory.values()
                    ),
                    "total_activities": self.being.memory.get_activity_count(),
                }
                current_state = self.being.state.get_current_state()
                is_config = self.being.is_configured()

                return {
                    "success": True,
                    "memory": memory_stats,
                    "state": current_state,
                    "is_configured": is_config,
                    "config": self.being.configs,
                }

            elif command == "get_activities":
                # Return loaded activities with 'enabled' status from activity_constraints
                acts = self.being.activity_loader.get_all_activities()
                info = {}

                activities_config = {}
                if (
                    "activity_constraints" in self.being.configs
                    and "activities_config"
                    in self.being.configs["activity_constraints"]
                ):
                    activities_config = self.being.configs["activity_constraints"][
                        "activities_config"
                    ]

                for module_name, cls in acts.items():
                    class_name = cls.__name__
                    is_enabled = True
                    if class_name in activities_config:
                        is_enabled = bool(
                            activities_config[class_name].get("enabled", True)
                        )

                    info[module_name] = {
                        "name": class_name,
                        "energy_cost": cls.energy_cost,
                        "cooldown": cls.cooldown,
                        "required_skills": cls.required_skills,
                        "last_execution": (
                            cls.last_execution.isoformat()
                            if cls.last_execution
                            else None
                        ),
                        "enabled": is_enabled,
                    }
                return {"success": True, "activities": info}

            elif command == "get_config":
                return {"success": True, "config": self.being.configs}

            elif command == "update_config":
                section = params.get("section")
                key = params.get("key")
                value = params.get("value")

                if not section or not key:
                    return {
                        "success": False,
                        "message": "Both 'section' and 'key' are required.",
                    }

                # Map sections to config files
                section_to_file = {
                    "character_config": "character_config.json",
                    "skills_config": "skills_config.json",
                    "activity_constraints": "activity_constraints.json",
                }

                config_file_name = section_to_file.get(section)
                if not config_file_name:
                    return {
                        "success": False,
                        "message": f"Unknown configuration section: {section}",
                    }

                config_path = Path(self.being.config_path) / config_file_name

                try:
                    if config_path.exists():
                        with open(config_path, "r") as f:
                            current_config = json.load(f)
                    else:
                        current_config = {}
                except json.JSONDecodeError as je:
                    logger.error(f"Failed to parse {config_file_name}: {je}")
                    return {
                        "success": False,
                        "message": f"Invalid JSON format in {config_file_name}.",
                    }
                except Exception as e:
                    logger.error(f"Error loading {config_file_name}: {e}")
                    return {
                        "success": False,
                        "message": f"Error loading {config_file_name}.",
                    }

                # Update the config
                current_config[key] = value

                # Write back
                try:
                    with open(config_path, "w") as f:
                        json.dump(current_config, f, indent=2)
                except Exception as e:
                    logger.error(f"Failed to write to {config_file_name}: {e}")
                    return {
                        "success": False,
                        "message": f"Failed to write to {config_file_name}.",
                    }

                # Update in-memory
                self.being.configs[section][key] = value
                logger.info(f"Updated config: [{section}] {key} = {value}")

                return {
                    "success": True,
                    "message": f"Configuration '{key}' updated successfully.",
                }

            elif command == "get_activity_history":
                limit = params.get("limit", 10)
                offset = params.get("offset", 0)
                recents = self.being.memory.get_recent_activities(limit=limit, offset=offset)
                total = self.being.memory.get_activity_count()
                return {
                    "success": True,
                    "activities": recents,
                    "has_more": total > (offset + limit),
                    "total": total,
                }

            elif command == "get_composio_app_actions":
                app_name = params.get("app_name")
                result = await api_manager.list_actions_for_app(app_name)
                if result.get("success"):
                    DynamicComposioSkills.register_composio_actions(
                        app_name, result.get("actions", [])
                    )
                return result

            elif command == "get_all_skills":
                config_skills = self.being.configs.get("skills_config", {})
                manual_skills_list = []
                for skill_name, skill_info in config_skills.items():
                    if not isinstance(skill_info, dict):
                        logger.debug(
                            f"Skipping non-dict skill config: {skill_name} => {skill_info}"
                        )
                        continue
                    manual_skills_list.append(
                        {
                            "skill_name": skill_name,
                            "enabled": bool(skill_info.get("enabled", False)),
                            "metadata": skill_info,
                        }
                    )

                dynamic_skills = DynamicComposioSkills.get_all_dynamic_skills()
                all_skills = manual_skills_list + dynamic_skills
                return {"success": True, "skills": all_skills}

            elif command == "get_activity_code":
                from framework.activity_loader import read_activity_code
                activity_name = params.get("activity_name")
                code_str = read_activity_code(activity_name)
                if code_str is None:
                    return {
                        "success": False,
                        "message": f"Could not read code for {activity_name}",
                    }
                return {"success": True, "code": code_str}

            elif command == "save_activity_code":
                from framework.activity_loader import write_activity_code
                activity_name = params.get("activity_name")
                new_code = params.get("new_code")
                ok = write_activity_code(activity_name, new_code)
                if not ok:
                    return {"success": False, "message": "Failed to save code"}
                self.being.activity_loader.reload_activities()
                return {"success": True, "message": "Code updated and reloaded"}

            elif command == "save_onboarding_data":
                """
                Expects 'character', 'skills', and 'constraints' from front-end.
                The 'skills' object may have e.g.:
                  {
                    "lite_llm": {
                      "enabled": true,
                      "model_name": "openai/gpt-4o",
                      "required_api_keys": ["LITELLM"],
                      "provided_api_key": "sk-1234abcd..."
                    },
                    "default_llm_skill": "lite_llm"
                  }
                """
                try:
                    char_data = params.get("character", {})
                    skills_data = params.get("skills", {})
                    constraints_data = params.get("constraints", {})

                    char_path = Path(self.being.config_path) / "character_config.json"
                    skill_path = Path(self.being.config_path) / "skills_config.json"
                    actc_path = Path(self.being.config_path) / "activity_constraints.json"

                    existing_char = {}
                    existing_skills = {}
                    existing_actc = {}

                    # Load existing JSON
                    if char_path.exists():
                        existing_char = json.loads(char_path.read_text(encoding="utf-8"))
                    if skill_path.exists():
                        existing_skills = json.loads(skill_path.read_text(encoding="utf-8"))
                    if actc_path.exists():
                        existing_actc = json.loads(actc_path.read_text(encoding="utf-8"))

                    # Merge the new data
                    existing_char.update(char_data)
                    existing_skills.update(skills_data)
                    for k, v in constraints_data.items():
                        existing_actc[k] = v

                    # Possibly set "setup_complete"
                    existing_char["setup_complete"] = True

                    # If user provided an API key for any skill, store it with secret manager
                    for skill_name, skill_info in skills_data.items():
                        if not isinstance(skill_info, dict):
                            continue
                        maybe_key = skill_info.get("provided_api_key")
                        if maybe_key:
                            required_keys = skill_info.get("required_api_keys", [])
                            if required_keys:
                                main_key = required_keys[0]
                                await api_manager.set_api_key(skill_name, main_key, maybe_key)

                            # Remove 'provided_api_key' from final JSON if you prefer
                            if "provided_api_key" in existing_skills[skill_name]:
                                del existing_skills[skill_name]["provided_api_key"]

                    # Save the updated JSON
                    char_path.write_text(json.dumps(existing_char, indent=2), encoding="utf-8")
                    skill_path.write_text(json.dumps(existing_skills, indent=2), encoding="utf-8")
                    actc_path.write_text(json.dumps(existing_actc, indent=2), encoding="utf-8")

                    # Reload in memory
                    self.being.configs["character_config"] = existing_char
                    self.being.configs["skills_config"] = existing_skills
                    self.being.configs["activity_constraints"] = existing_actc

                    return {"success": True, "message": "Onboarding data saved."}

                except Exception as e:
                    logger.error(f"Error saving onboarding data: {e}", exc_info=True)
                    return {"success": False, "message": str(e)}

            elif command == "get_auth_schemes":
                app_name = params.get("app_name")
                if not app_name:
                    return {"success": False, "error": "Missing app_name"}
                try:
                    result = await api_manager.get_auth_schemes(app_name)
                    return result
                except Exception as e:
                    logger.error(f"get_auth_schemes error: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "initiate_api_key_connection":
                app_name = params.get("app_name")
                connection_params = params.get("connection_params")
                if not app_name or not connection_params:
                    return {"success": False, "error": "Missing app_name or connection_params"}
                try:
                    result = await api_manager.initiate_api_key_connection(app_name, connection_params)
                    return result
                except Exception as e:
                    logger.error(f"initiate_api_key_connection error: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "initiate_oauth_with_params":
                app_name = params.get("app_name")
                base_url = params.get("base_url", "http://localhost:8000")
                connection_params = params.get("connection_params")
                if not app_name or not connection_params:
                    return {"success": False, "error": "Missing app_name or connection_params"}
                redirect_url = f"{base_url}/oauth_callback"
                try:
                    result = await api_manager.composio_manager.initiate_oauth_with_params(
                        app_name, redirect_url, connection_params
                    )
                    return result
                except Exception as e:
                    logger.error(f"initiate_oauth_with_params error: {e}")
                    return {"success": False, "error": str(e)}

        except Exception as e:
            logger.error(f"handle_command {command} error: {e}")
            return {"success": False, "message": str(e)}

        return {"success": False, "message": "Unknown command"}

    async def broadcast_state(self):
        """Broadcast the current being_state to all connected WebSocket clients."""
        if not self.clients:
            return
        message = json.dumps({"type": "state_update", "data": self.being_state})
        disconnected_clients = set()
        for client in self.clients:
            try:
                await client.send(message)
            except websockets.ConnectionClosed:
                logger.info("Client disconnected during broadcast")
                disconnected_clients.add(client)
            except Exception as e:
                logger.error(f"Error broadcasting to client: {e}")
                disconnected_clients.add(client)

        for dc in disconnected_clients:
            await self.unregister(dc)

    async def start_server(self):
        """Start the server using websockets.serve()."""
        try:
            await self.initialize()
            async with serve(
                self.handle_websocket,
                self.host,
                self.port,
                process_request=self.serve_static_file,
            ):
                logger.info(f"Server started on ws://{self.host}:{self.port}")
                await asyncio.Future()  # run forever
        except Exception as e:
            logger.error(f"Failed to start server: {e}")
            raise


if __name__ == "__main__":
    server = DigitalBeingServer()
    asyncio.run(server.start_server())

